[
    {
        "loss": 0.6852,
        "grad_norm": 79.86377716064453,
        "learning_rate": 4.932634730538922e-07,
        "rewards/chosen": 0.9527994990348816,
        "rewards/rejected": 0.6868489384651184,
        "rewards/accuracies": 0.625,
        "rewards/margins": 0.26622721552848816,
        "logps/chosen": -249.74166870117188,
        "logps/rejected": -217.12083435058594,
        "logits/chosen": -0.7729573845863342,
        "logits/rejected": -0.727343738079071,
        "epoch": 0.03,
        "step": 10
    },
    {
        "eval_loss": 0.5674999952316284,
        "eval_runtime": 8.3326,
        "eval_samples_per_second": 12.001,
        "eval_steps_per_second": 1.56,
        "eval_rewards/chosen": 0.7292668223381042,
        "eval_rewards/rejected": 0.41383713483810425,
        "eval_rewards/accuracies": 0.75,
        "eval_rewards/margins": 0.3148287236690521,
        "eval_logps/chosen": -292.5,
        "eval_logps/rejected": -268.19232177734375,
        "eval_logits/chosen": -0.8608773946762085,
        "eval_logits/rejected": -0.9191706776618958,
        "epoch": 0.03,
        "step": 10
    },
    {
        "loss": 0.6911,
        "grad_norm": 68.15670776367188,
        "learning_rate": 4.857784431137724e-07,
        "rewards/chosen": 0.703906238079071,
        "rewards/rejected": 0.5196614861488342,
        "rewards/accuracies": 0.5666666626930237,
        "rewards/margins": 0.18463541567325592,
        "logps/chosen": -270.7708435058594,
        "logps/rejected": -275.1791687011719,
        "logits/chosen": -0.7954427003860474,
        "logits/rejected": -0.7935546636581421,
        "epoch": 0.06,
        "step": 20
    },
    {
        "eval_loss": 0.5737890601158142,
        "eval_runtime": 8.3698,
        "eval_samples_per_second": 11.948,
        "eval_steps_per_second": 1.553,
        "eval_rewards/chosen": 0.5024038553237915,
        "eval_rewards/rejected": 0.19411996006965637,
        "eval_rewards/accuracies": 0.7403846383094788,
        "eval_rewards/margins": 0.30844351649284363,
        "eval_logps/chosen": -294.73077392578125,
        "eval_logps/rejected": -270.4230651855469,
        "eval_logits/chosen": -0.8626803159713745,
        "eval_logits/rejected": -0.9197716116905212,
        "epoch": 0.06,
        "step": 20
    },
    {
        "loss": 0.8291,
        "grad_norm": 63.34827423095703,
        "learning_rate": 4.782934131736526e-07,
        "rewards/chosen": 0.4991617798805237,
        "rewards/rejected": 0.21155191957950592,
        "rewards/accuracies": 0.5916666388511658,
        "rewards/margins": 0.2877604067325592,
        "logps/chosen": -373.875,
        "logps/rejected": -244.73333740234375,
        "logits/chosen": -0.803466796875,
        "logits/rejected": -0.7802083492279053,
        "epoch": 0.09,
        "step": 30
    },
    {
        "eval_loss": 0.5670703053474426,
        "eval_runtime": 8.3908,
        "eval_samples_per_second": 11.918,
        "eval_steps_per_second": 1.549,
        "eval_rewards/chosen": 0.42307692766189575,
        "eval_rewards/rejected": 0.09736985713243484,
        "eval_rewards/accuracies": 0.7019230723381042,
        "eval_rewards/margins": 0.3257587254047394,
        "eval_logps/chosen": -295.8461608886719,
        "eval_logps/rejected": -271.3461608886719,
        "eval_logits/chosen": -0.8653846383094788,
        "eval_logits/rejected": -0.9239783883094788,
        "epoch": 0.09,
        "step": 30
    },
    {
        "loss": 0.7271,
        "grad_norm": 89.65435028076172,
        "learning_rate": 4.708083832335329e-07,
        "rewards/chosen": 0.5703165531158447,
        "rewards/rejected": 0.311767578125,
        "rewards/accuracies": 0.574999988079071,
        "rewards/margins": 0.2584472596645355,
        "logps/chosen": -298.29998779296875,
        "logps/rejected": -280.7458190917969,
        "logits/chosen": -0.863085925579071,
        "logits/rejected": -0.8643880486488342,
        "epoch": 0.12,
        "step": 40
    },
    {
        "eval_loss": 0.5565234422683716,
        "eval_runtime": 8.4052,
        "eval_samples_per_second": 11.897,
        "eval_steps_per_second": 1.547,
        "eval_rewards/chosen": 0.38934797048568726,
        "eval_rewards/rejected": 0.035320576280355453,
        "eval_rewards/accuracies": 0.7115384340286255,
        "eval_rewards/margins": 0.3540414571762085,
        "eval_logps/chosen": -296.1538391113281,
        "eval_logps/rejected": -271.6538391113281,
        "eval_logits/chosen": -0.8656851053237915,
        "eval_logits/rejected": -0.9245793223381042,
        "epoch": 0.12,
        "step": 40
    },
    {
        "loss": 0.6883,
        "grad_norm": 86.19428253173828,
        "learning_rate": 4.6332335329341315e-07,
        "rewards/chosen": 0.47708332538604736,
        "rewards/rejected": 0.14685465395450592,
        "rewards/accuracies": 0.625,
        "rewards/margins": 0.330322265625,
        "logps/chosen": -263.01666259765625,
        "logps/rejected": -264.6833190917969,
        "logits/chosen": -0.8225260376930237,
        "logits/rejected": -0.7962728142738342,
        "epoch": 0.15,
        "step": 50
    },
    {
        "eval_loss": 0.5561327934265137,
        "eval_runtime": 8.398,
        "eval_samples_per_second": 11.908,
        "eval_steps_per_second": 1.548,
        "eval_rewards/chosen": 0.29052734375,
        "eval_rewards/rejected": -0.06292255222797394,
        "eval_rewards/accuracies": 0.7115384340286255,
        "eval_rewards/margins": 0.35357195138931274,
        "eval_logps/chosen": -297.0769348144531,
        "eval_logps/rejected": -273.0384521484375,
        "eval_logits/chosen": -0.868088960647583,
        "eval_logits/rejected": -0.9269831776618958,
        "epoch": 0.15,
        "step": 50
    },
    {
        "loss": 0.5414,
        "grad_norm": 72.4068832397461,
        "learning_rate": 4.558383233532934e-07,
        "rewards/chosen": 0.4567057192325592,
        "rewards/rejected": -0.0063720704056322575,
        "rewards/accuracies": 0.7416666746139526,
        "rewards/margins": 0.46296387910842896,
        "logps/chosen": -222.93333435058594,
        "logps/rejected": -221.23333740234375,
        "logits/chosen": -0.8840169310569763,
        "logits/rejected": -0.8157308101654053,
        "epoch": 0.18,
        "step": 60
    },
    {
        "eval_loss": 0.5420117378234863,
        "eval_runtime": 8.4102,
        "eval_samples_per_second": 11.89,
        "eval_steps_per_second": 1.546,
        "eval_rewards/chosen": 0.33413460850715637,
        "eval_rewards/rejected": -0.06695556640625,
        "eval_rewards/accuracies": 0.7211538553237915,
        "eval_rewards/margins": 0.4012920558452606,
        "eval_logps/chosen": -296.5,
        "eval_logps/rejected": -273.19232177734375,
        "eval_logits/chosen": -0.8734976053237915,
        "eval_logits/rejected": -0.9311898946762085,
        "epoch": 0.18,
        "step": 60
    },
    {
        "loss": 0.5912,
        "grad_norm": 66.64468383789062,
        "learning_rate": 4.483532934131736e-07,
        "rewards/chosen": 0.551953136920929,
        "rewards/rejected": 0.08734537661075592,
        "rewards/accuracies": 0.6666666865348816,
        "rewards/margins": 0.4648895263671875,
        "logps/chosen": -304.98333740234375,
        "logps/rejected": -285.8666687011719,
        "logits/chosen": -0.8202311396598816,
        "logits/rejected": -0.8363606929779053,
        "epoch": 0.21,
        "step": 70
    },
    {
        "eval_loss": 0.5481250286102295,
        "eval_runtime": 8.4159,
        "eval_samples_per_second": 11.882,
        "eval_steps_per_second": 1.545,
        "eval_rewards/chosen": 0.4346454441547394,
        "eval_rewards/rejected": 0.04278564453125,
        "eval_rewards/accuracies": 0.7115384340286255,
        "eval_rewards/margins": 0.39088791608810425,
        "eval_logps/chosen": -295.6538391113281,
        "eval_logps/rejected": -271.8846130371094,
        "eval_logits/chosen": -0.878004789352417,
        "eval_logits/rejected": -0.9353966116905212,
        "epoch": 0.21,
        "step": 70
    },
    {
        "loss": 0.5762,
        "grad_norm": 42.78704833984375,
        "learning_rate": 4.408682634730539e-07,
        "rewards/chosen": 0.6675130128860474,
        "rewards/rejected": 0.23595377802848816,
        "rewards/accuracies": 0.675000011920929,
        "rewards/margins": 0.430908203125,
        "logps/chosen": -240.27499389648438,
        "logps/rejected": -217.09165954589844,
        "logits/chosen": -0.7532714605331421,
        "logits/rejected": -0.7393554449081421,
        "epoch": 0.24,
        "step": 80
    },
    {
        "eval_loss": 0.5357812643051147,
        "eval_runtime": 8.4171,
        "eval_samples_per_second": 11.881,
        "eval_steps_per_second": 1.544,
        "eval_rewards/chosen": 0.5814303159713745,
        "eval_rewards/rejected": 0.15439078211784363,
        "eval_rewards/accuracies": 0.7692307829856873,
        "eval_rewards/margins": 0.42660757899284363,
        "eval_logps/chosen": -293.9615478515625,
        "eval_logps/rejected": -270.8846130371094,
        "eval_logits/chosen": -0.8804086446762085,
        "eval_logits/rejected": -0.9362980723381042,
        "epoch": 0.24,
        "step": 80
    },
    {
        "loss": 0.8384,
        "grad_norm": 84.5681381225586,
        "learning_rate": 4.333832335329341e-07,
        "rewards/chosen": 0.602783203125,
        "rewards/rejected": 0.4907124936580658,
        "rewards/accuracies": 0.5833333134651184,
        "rewards/margins": 0.11186523735523224,
        "logps/chosen": -269.57916259765625,
        "logps/rejected": -256.8666687011719,
        "logits/chosen": -0.7553060054779053,
        "logits/rejected": -0.7386230230331421,
        "epoch": 0.27,
        "step": 90
    },
    {
        "eval_loss": 0.5218945145606995,
        "eval_runtime": 8.4216,
        "eval_samples_per_second": 11.874,
        "eval_steps_per_second": 1.544,
        "eval_rewards/chosen": 0.6926081776618958,
        "eval_rewards/rejected": 0.22483474016189575,
        "eval_rewards/accuracies": 0.7788461446762085,
        "eval_rewards/margins": 0.46694710850715637,
        "eval_logps/chosen": -292.80767822265625,
        "eval_logps/rejected": -270.30767822265625,
        "eval_logits/chosen": -0.8810096383094788,
        "eval_logits/rejected": -0.9371995329856873,
        "epoch": 0.27,
        "step": 90
    },
    {
        "loss": 0.7526,
        "grad_norm": 73.06244659423828,
        "learning_rate": 4.2589820359281434e-07,
        "rewards/chosen": 0.6519857048988342,
        "rewards/rejected": 0.4670003354549408,
        "rewards/accuracies": 0.6083333492279053,
        "rewards/margins": 0.18430989980697632,
        "logps/chosen": -304.9166564941406,
        "logps/rejected": -342.4166564941406,
        "logits/chosen": -0.8013671636581421,
        "logits/rejected": -0.8383463621139526,
        "epoch": 0.3,
        "step": 100
    },
    {
        "eval_loss": 0.5371484160423279,
        "eval_runtime": 8.4246,
        "eval_samples_per_second": 11.87,
        "eval_steps_per_second": 1.543,
        "eval_rewards/chosen": 0.46011117100715637,
        "eval_rewards/rejected": 0.022348256781697273,
        "eval_rewards/accuracies": 0.7211538553237915,
        "eval_rewards/margins": 0.43776291608810425,
        "eval_logps/chosen": -295.4230651855469,
        "eval_logps/rejected": -272.23077392578125,
        "eval_logits/chosen": -0.8846153616905212,
        "eval_logits/rejected": -0.9402043223381042,
        "epoch": 0.3,
        "step": 100
    },
    {
        "loss": 0.8606,
        "grad_norm": 56.73050308227539,
        "learning_rate": 4.184131736526946e-07,
        "rewards/chosen": 0.3426106870174408,
        "rewards/rejected": 0.32972005009651184,
        "rewards/accuracies": 0.5249999761581421,
        "rewards/margins": 0.013151041232049465,
        "logps/chosen": -259.38751220703125,
        "logps/rejected": -242.4875030517578,
        "logits/chosen": -0.71875,
        "logits/rejected": -0.736328125,
        "epoch": 0.33,
        "step": 110
    },
    {
        "eval_loss": 0.5217187404632568,
        "eval_runtime": 8.3992,
        "eval_samples_per_second": 11.906,
        "eval_steps_per_second": 1.548,
        "eval_rewards/chosen": 0.2730619013309479,
        "eval_rewards/rejected": -0.19482421875,
        "eval_rewards/accuracies": 0.692307710647583,
        "eval_rewards/margins": 0.46754807233810425,
        "eval_logps/chosen": -297.23077392578125,
        "eval_logps/rejected": -274.26922607421875,
        "eval_logits/chosen": -0.885817289352417,
        "eval_logits/rejected": -0.9420071840286255,
        "epoch": 0.33,
        "step": 110
    },
    {
        "loss": 0.672,
        "grad_norm": 67.81355285644531,
        "learning_rate": 4.1092814371257486e-07,
        "rewards/chosen": 0.3022054135799408,
        "rewards/rejected": -0.12052001804113388,
        "rewards/accuracies": 0.625,
        "rewards/margins": 0.42263996601104736,
        "logps/chosen": -257.14166259765625,
        "logps/rejected": -258.6333312988281,
        "logits/chosen": -0.7493367791175842,
        "logits/rejected": -0.7324381470680237,
        "epoch": 0.36,
        "step": 120
    },
    {
        "eval_loss": 0.5323241949081421,
        "eval_runtime": 8.4083,
        "eval_samples_per_second": 11.893,
        "eval_steps_per_second": 1.546,
        "eval_rewards/chosen": -0.0482177734375,
        "eval_rewards/rejected": -0.48324820399284363,
        "eval_rewards/accuracies": 0.7692307829856873,
        "eval_rewards/margins": 0.4350961446762085,
        "eval_logps/chosen": -300.4230651855469,
        "eval_logps/rejected": -277.30767822265625,
        "eval_logits/chosen": -0.8873196840286255,
        "eval_logits/rejected": -0.9438101053237915,
        "epoch": 0.36,
        "step": 120
    },
    {
        "loss": 0.7237,
        "grad_norm": 113.29325866699219,
        "learning_rate": 4.0344311377245507e-07,
        "rewards/chosen": -0.04485270008444786,
        "rewards/rejected": -0.3091634213924408,
        "rewards/accuracies": 0.574999988079071,
        "rewards/margins": 0.26443684101104736,
        "logps/chosen": -303.6000061035156,
        "logps/rejected": -233.19166564941406,
        "logits/chosen": -0.8193033933639526,
        "logits/rejected": -0.7891927361488342,
        "epoch": 0.39,
        "step": 130
    },
    {
        "eval_loss": 0.5392187237739563,
        "eval_runtime": 8.3964,
        "eval_samples_per_second": 11.91,
        "eval_steps_per_second": 1.548,
        "eval_rewards/chosen": -0.19680550694465637,
        "eval_rewards/rejected": -0.6068960428237915,
        "eval_rewards/accuracies": 0.7596153616905212,
        "eval_rewards/margins": 0.40993088483810425,
        "eval_logps/chosen": -301.5769348144531,
        "eval_logps/rejected": -278.1153869628906,
        "eval_logits/chosen": -0.8885216116905212,
        "eval_logits/rejected": -0.9447115659713745,
        "epoch": 0.39,
        "step": 130
    },
    {
        "loss": 0.6633,
        "grad_norm": 77.25660705566406,
        "learning_rate": 3.959580838323353e-07,
        "rewards/chosen": -0.22607015073299408,
        "rewards/rejected": -0.5525227785110474,
        "rewards/accuracies": 0.6166666746139526,
        "rewards/margins": 0.32620441913604736,
        "logps/chosen": -243.75416564941406,
        "logps/rejected": -241.50833129882812,
        "logits/chosen": -0.7938150763511658,
        "logits/rejected": -0.8037109375,
        "epoch": 0.42,
        "step": 140
    },
    {
        "eval_loss": 0.5497265458106995,
        "eval_runtime": 8.3865,
        "eval_samples_per_second": 11.924,
        "eval_steps_per_second": 1.55,
        "eval_rewards/chosen": -0.3125,
        "eval_rewards/rejected": -0.70703125,
        "eval_rewards/accuracies": 0.75,
        "eval_rewards/margins": 0.39438101649284363,
        "eval_logps/chosen": -303.4230651855469,
        "eval_logps/rejected": -279.3846130371094,
        "eval_logits/chosen": -0.8909254670143127,
        "eval_logits/rejected": -0.946213960647583,
        "epoch": 0.42,
        "step": 140
    },
    {
        "loss": 0.6503,
        "grad_norm": 36.145912170410156,
        "learning_rate": 3.884730538922156e-07,
        "rewards/chosen": -0.06015624850988388,
        "rewards/rejected": -0.6066243648529053,
        "rewards/accuracies": 0.5833333134651184,
        "rewards/margins": 0.5458658933639526,
        "logps/chosen": -371.1666564941406,
        "logps/rejected": -279.375,
        "logits/chosen": -0.7419453859329224,
        "logits/rejected": -0.7768229246139526,
        "epoch": 0.45,
        "step": 150
    },
    {
        "eval_loss": 0.5407812595367432,
        "eval_runtime": 8.3797,
        "eval_samples_per_second": 11.934,
        "eval_steps_per_second": 1.551,
        "eval_rewards/chosen": -0.4399038553237915,
        "eval_rewards/rejected": -0.8326321840286255,
        "eval_rewards/accuracies": 0.7884615659713745,
        "eval_rewards/margins": 0.3925029933452606,
        "eval_logps/chosen": -304.3846130371094,
        "eval_logps/rejected": -280.6153869628906,
        "eval_logits/chosen": -0.8900240659713745,
        "eval_logits/rejected": -0.9459134340286255,
        "epoch": 0.45,
        "step": 150
    },
    {
        "loss": 0.6942,
        "grad_norm": 100.94973754882812,
        "learning_rate": 3.809880239520958e-07,
        "rewards/chosen": -0.39016926288604736,
        "rewards/rejected": -0.7250000238418579,
        "rewards/accuracies": 0.5833333134651184,
        "rewards/margins": 0.3344889283180237,
        "logps/chosen": -274.07501220703125,
        "logps/rejected": -268.9333190917969,
        "logits/chosen": -0.8902343511581421,
        "logits/rejected": -0.9039062261581421,
        "epoch": 0.48,
        "step": 160
    },
    {
        "eval_loss": 0.5551171898841858,
        "eval_runtime": 8.3854,
        "eval_samples_per_second": 11.926,
        "eval_steps_per_second": 1.55,
        "eval_rewards/chosen": -0.5078125,
        "eval_rewards/rejected": -0.8638821840286255,
        "eval_rewards/accuracies": 0.7596153616905212,
        "eval_rewards/margins": 0.35561898350715637,
        "eval_logps/chosen": -305.23077392578125,
        "eval_logps/rejected": -280.9615478515625,
        "eval_logits/chosen": -0.8882211446762085,
        "eval_logits/rejected": -0.9450120329856873,
        "epoch": 0.48,
        "step": 160
    },
    {
        "loss": 0.7085,
        "grad_norm": 101.08842468261719,
        "learning_rate": 3.7350299401197605e-07,
        "rewards/chosen": -0.2769612669944763,
        "rewards/rejected": -0.671679675579071,
        "rewards/accuracies": 0.574999988079071,
        "rewards/margins": 0.39440104365348816,
        "logps/chosen": -336.8666687011719,
        "logps/rejected": -318.7083435058594,
        "logits/chosen": -0.9306640625,
        "logits/rejected": -0.883984386920929,
        "epoch": 0.51,
        "step": 170
    },
    {
        "eval_loss": 0.555859386920929,
        "eval_runtime": 8.4276,
        "eval_samples_per_second": 11.866,
        "eval_steps_per_second": 1.543,
        "eval_rewards/chosen": -0.49594351649284363,
        "eval_rewards/rejected": -0.8539663553237915,
        "eval_rewards/accuracies": 0.7692307829856873,
        "eval_rewards/margins": 0.35869890451431274,
        "eval_logps/chosen": -305.0384521484375,
        "eval_logps/rejected": -280.80767822265625,
        "eval_logits/chosen": -0.8870192170143127,
        "eval_logits/rejected": -0.9435096383094788,
        "epoch": 0.51,
        "step": 170
    },
    {
        "loss": 0.6798,
        "grad_norm": 79.28877258300781,
        "learning_rate": 3.6601796407185626e-07,
        "rewards/chosen": -0.2880452573299408,
        "rewards/rejected": -0.7944661378860474,
        "rewards/accuracies": 0.6333333253860474,
        "rewards/margins": 0.5064941644668579,
        "logps/chosen": -280.4666748046875,
        "logps/rejected": -257.5,
        "logits/chosen": -0.8635579347610474,
        "logits/rejected": -0.8477538824081421,
        "epoch": 0.54,
        "step": 180
    },
    {
        "eval_loss": 0.5546875,
        "eval_runtime": 8.4321,
        "eval_samples_per_second": 11.859,
        "eval_steps_per_second": 1.542,
        "eval_rewards/chosen": -0.4497445821762085,
        "eval_rewards/rejected": -0.8200120329856873,
        "eval_rewards/accuracies": 0.7692307829856873,
        "eval_rewards/margins": 0.3705679178237915,
        "eval_logps/chosen": -304.26922607421875,
        "eval_logps/rejected": -280.4615478515625,
        "eval_logits/chosen": -0.883713960647583,
        "eval_logits/rejected": -0.940504789352417,
        "epoch": 0.54,
        "step": 180
    },
    {
        "loss": 0.687,
        "grad_norm": 66.36052703857422,
        "learning_rate": 3.585329341317365e-07,
        "rewards/chosen": -0.31688639521598816,
        "rewards/rejected": -0.6698405146598816,
        "rewards/accuracies": 0.5249999761581421,
        "rewards/margins": 0.3524414002895355,
        "logps/chosen": -270.2833251953125,
        "logps/rejected": -295.6333312988281,
        "logits/chosen": -0.7904947996139526,
        "logits/rejected": -0.7458658814430237,
        "epoch": 0.57,
        "step": 190
    },
    {
        "eval_loss": 0.5546484589576721,
        "eval_runtime": 8.4229,
        "eval_samples_per_second": 11.872,
        "eval_steps_per_second": 1.543,
        "eval_rewards/chosen": -0.4707782566547394,
        "eval_rewards/rejected": -0.8356370329856873,
        "eval_rewards/accuracies": 0.7307692170143127,
        "eval_rewards/margins": 0.36545974016189575,
        "eval_logps/chosen": -304.6538391113281,
        "eval_logps/rejected": -280.69232177734375,
        "eval_logits/chosen": -0.8825120329856873,
        "eval_logits/rejected": -0.9393028616905212,
        "epoch": 0.57,
        "step": 190
    },
    {
        "loss": 0.5829,
        "grad_norm": 43.30950164794922,
        "learning_rate": 3.510479041916167e-07,
        "rewards/chosen": -0.19213256239891052,
        "rewards/rejected": -0.7046549320220947,
        "rewards/accuracies": 0.625,
        "rewards/margins": 0.5123941898345947,
        "logps/chosen": -252.98333740234375,
        "logps/rejected": -283.76666259765625,
        "logits/chosen": -0.8147135376930237,
        "logits/rejected": -0.8326823115348816,
        "epoch": 0.6,
        "step": 200
    },
    {
        "eval_loss": 0.5523046851158142,
        "eval_runtime": 8.4214,
        "eval_samples_per_second": 11.874,
        "eval_steps_per_second": 1.544,
        "eval_rewards/chosen": -0.47723859548568726,
        "eval_rewards/rejected": -0.8539663553237915,
        "eval_rewards/accuracies": 0.7692307829856873,
        "eval_rewards/margins": 0.37620192766189575,
        "eval_logps/chosen": -304.8846130371094,
        "eval_logps/rejected": -280.8846130371094,
        "eval_logits/chosen": -0.8864182829856873,
        "eval_logits/rejected": -0.9432091116905212,
        "epoch": 0.6,
        "step": 200
    },
    {
        "loss": 0.7767,
        "grad_norm": 69.81295013427734,
        "learning_rate": 3.43562874251497e-07,
        "rewards/chosen": -0.5166015625,
        "rewards/rejected": -0.7111979126930237,
        "rewards/accuracies": 0.6083333492279053,
        "rewards/margins": 0.19464924931526184,
        "logps/chosen": -254.88333129882812,
        "logps/rejected": -236.38333129882812,
        "logits/chosen": -0.8394531011581421,
        "logits/rejected": -0.8147786259651184,
        "epoch": 0.63,
        "step": 210
    },
    {
        "eval_loss": 0.5388281345367432,
        "eval_runtime": 8.4244,
        "eval_samples_per_second": 11.87,
        "eval_steps_per_second": 1.543,
        "eval_rewards/chosen": -0.4429086446762085,
        "eval_rewards/rejected": -0.8569711446762085,
        "eval_rewards/accuracies": 0.7596153616905212,
        "eval_rewards/margins": 0.4134615361690521,
        "eval_logps/chosen": -304.26922607421875,
        "eval_logps/rejected": -280.80767822265625,
        "eval_logits/chosen": -0.8864182829856873,
        "eval_logits/rejected": -0.9426081776618958,
        "epoch": 0.63,
        "step": 210
    },
    {
        "loss": 0.7747,
        "grad_norm": 44.86249923706055,
        "learning_rate": 3.3607784431137724e-07,
        "rewards/chosen": -0.3532918393611908,
        "rewards/rejected": -0.5381022095680237,
        "rewards/accuracies": 0.5083333253860474,
        "rewards/margins": 0.184814453125,
        "logps/chosen": -274.5666809082031,
        "logps/rejected": -268.29998779296875,
        "logits/chosen": -0.7649088501930237,
        "logits/rejected": -0.7522786259651184,
        "epoch": 0.66,
        "step": 220
    },
    {
        "eval_loss": 0.543652355670929,
        "eval_runtime": 8.4318,
        "eval_samples_per_second": 11.86,
        "eval_steps_per_second": 1.542,
        "eval_rewards/chosen": -0.4263070821762085,
        "eval_rewards/rejected": -0.8263221383094788,
        "eval_rewards/accuracies": 0.75,
        "eval_rewards/margins": 0.40121695399284363,
        "eval_logps/chosen": -304.0384521484375,
        "eval_logps/rejected": -280.5769348144531,
        "eval_logits/chosen": -0.8855168223381042,
        "eval_logits/rejected": -0.942307710647583,
        "epoch": 0.66,
        "step": 220
    },
    {
        "loss": 0.7244,
        "grad_norm": 31.36576271057129,
        "learning_rate": 3.2859281437125745e-07,
        "rewards/chosen": -0.23670247197151184,
        "rewards/rejected": -0.6061441898345947,
        "rewards/accuracies": 0.6083333492279053,
        "rewards/margins": 0.3701009154319763,
        "logps/chosen": -305.51666259765625,
        "logps/rejected": -271.3333435058594,
        "logits/chosen": -0.7240152955055237,
        "logits/rejected": -0.7152465581893921,
        "epoch": 0.69,
        "step": 230
    },
    {
        "eval_loss": 0.5480077862739563,
        "eval_runtime": 8.4296,
        "eval_samples_per_second": 11.863,
        "eval_steps_per_second": 1.542,
        "eval_rewards/chosen": -0.43096452951431274,
        "eval_rewards/rejected": -0.815504789352417,
        "eval_rewards/accuracies": 0.7115384340286255,
        "eval_rewards/margins": 0.3846904933452606,
        "eval_logps/chosen": -304.30767822265625,
        "eval_logps/rejected": -280.5384521484375,
        "eval_logits/chosen": -0.8831129670143127,
        "eval_logits/rejected": -0.940504789352417,
        "epoch": 0.69,
        "step": 230
    },
    {
        "loss": 0.603,
        "grad_norm": 73.4004135131836,
        "learning_rate": 3.211077844311377e-07,
        "rewards/chosen": -0.2717081606388092,
        "rewards/rejected": -0.7564778923988342,
        "rewards/accuracies": 0.6833333373069763,
        "rewards/margins": 0.48504638671875,
        "logps/chosen": -329.0666809082031,
        "logps/rejected": -257.4666748046875,
        "logits/chosen": -0.8110026121139526,
        "logits/rejected": -0.800341784954071,
        "epoch": 0.72,
        "step": 240
    },
    {
        "eval_loss": 0.5445312261581421,
        "eval_runtime": 8.4251,
        "eval_samples_per_second": 11.869,
        "eval_steps_per_second": 1.543,
        "eval_rewards/chosen": -0.4370492696762085,
        "eval_rewards/rejected": -0.8488581776618958,
        "eval_rewards/accuracies": 0.75,
        "eval_rewards/margins": 0.4116586446762085,
        "eval_logps/chosen": -304.19232177734375,
        "eval_logps/rejected": -280.8846130371094,
        "eval_logits/chosen": -0.8834134340286255,
        "eval_logits/rejected": -0.9417067170143127,
        "epoch": 0.72,
        "step": 240
    },
    {
        "loss": 0.6972,
        "grad_norm": 59.226593017578125,
        "learning_rate": 3.136227544910179e-07,
        "rewards/chosen": -0.27062785625457764,
        "rewards/rejected": -0.5797037482261658,
        "rewards/accuracies": 0.5916666388511658,
        "rewards/margins": 0.3093505799770355,
        "logps/chosen": -256.8083190917969,
        "logps/rejected": -239.14999389648438,
        "logits/chosen": -0.8673177361488342,
        "logits/rejected": -0.8695963621139526,
        "epoch": 0.75,
        "step": 250
    },
    {
        "eval_loss": 0.5408594012260437,
        "eval_runtime": 8.4174,
        "eval_samples_per_second": 11.88,
        "eval_steps_per_second": 1.544,
        "eval_rewards/chosen": -0.4515474736690521,
        "eval_rewards/rejected": -0.8673377633094788,
        "eval_rewards/accuracies": 0.7596153616905212,
        "eval_rewards/margins": 0.4144380986690521,
        "eval_logps/chosen": -304.26922607421875,
        "eval_logps/rejected": -280.9615478515625,
        "eval_logits/chosen": -0.8831129670143127,
        "eval_logits/rejected": -0.9408053159713745,
        "epoch": 0.75,
        "step": 250
    },
    {
        "loss": 0.6313,
        "grad_norm": 121.22627258300781,
        "learning_rate": 3.0613772455089823e-07,
        "rewards/chosen": -0.2844034731388092,
        "rewards/rejected": -0.6193603277206421,
        "rewards/accuracies": 0.6166666746139526,
        "rewards/margins": 0.3350585997104645,
        "logps/chosen": -237.10000610351562,
        "logps/rejected": -206.72500610351562,
        "logits/chosen": -0.9059895873069763,
        "logits/rejected": -0.8733072876930237,
        "epoch": 0.78,
        "step": 260
    },
    {
        "eval_loss": 0.5269922018051147,
        "eval_runtime": 8.3822,
        "eval_samples_per_second": 11.93,
        "eval_steps_per_second": 1.551,
        "eval_rewards/chosen": -0.36305588483810425,
        "eval_rewards/rejected": -0.8106971383094788,
        "eval_rewards/accuracies": 0.7403846383094788,
        "eval_rewards/margins": 0.4477163553237915,
        "eval_logps/chosen": -303.8461608886719,
        "eval_logps/rejected": -280.3461608886719,
        "eval_logits/chosen": -0.8843148946762085,
        "eval_logits/rejected": -0.9420071840286255,
        "epoch": 0.78,
        "step": 260
    },
    {
        "loss": 0.6592,
        "grad_norm": 50.37550354003906,
        "learning_rate": 2.9865269461077843e-07,
        "rewards/chosen": -0.24178873002529144,
        "rewards/rejected": -0.6535074710845947,
        "rewards/accuracies": 0.6333333253860474,
        "rewards/margins": 0.4107218384742737,
        "logps/chosen": -253.8333282470703,
        "logps/rejected": -252.01666259765625,
        "logits/chosen": -0.8106771111488342,
        "logits/rejected": -0.8413411378860474,
        "epoch": 0.81,
        "step": 270
    },
    {
        "eval_loss": 0.5193164348602295,
        "eval_runtime": 8.4168,
        "eval_samples_per_second": 11.881,
        "eval_steps_per_second": 1.545,
        "eval_rewards/chosen": -0.2723247706890106,
        "eval_rewards/rejected": -0.739332914352417,
        "eval_rewards/accuracies": 0.7980769276618958,
        "eval_rewards/margins": 0.46664664149284363,
        "eval_logps/chosen": -302.69232177734375,
        "eval_logps/rejected": -279.80767822265625,
        "eval_logits/chosen": -0.8852163553237915,
        "eval_logits/rejected": -0.9420071840286255,
        "epoch": 0.81,
        "step": 270
    },
    {
        "loss": 0.6457,
        "grad_norm": 86.6650161743164,
        "learning_rate": 2.911676646706587e-07,
        "rewards/chosen": -0.0840860977768898,
        "rewards/rejected": -0.5117390751838684,
        "rewards/accuracies": 0.6333333253860474,
        "rewards/margins": 0.4277750551700592,
        "logps/chosen": -248.01666259765625,
        "logps/rejected": -252.28334045410156,
        "logits/chosen": -0.8031901121139526,
        "logits/rejected": -0.7404622435569763,
        "epoch": 0.84,
        "step": 280
    },
    {
        "eval_loss": 0.5269922018051147,
        "eval_runtime": 8.4142,
        "eval_samples_per_second": 11.885,
        "eval_steps_per_second": 1.545,
        "eval_rewards/chosen": -0.25042253732681274,
        "eval_rewards/rejected": -0.7037259340286255,
        "eval_rewards/accuracies": 0.7692307829856873,
        "eval_rewards/margins": 0.4536508321762085,
        "eval_logps/chosen": -302.4615478515625,
        "eval_logps/rejected": -279.5384521484375,
        "eval_logits/chosen": -0.8843148946762085,
        "eval_logits/rejected": -0.942307710647583,
        "epoch": 0.84,
        "step": 280
    },
    {
        "loss": 0.7913,
        "grad_norm": 30.36948585510254,
        "learning_rate": 2.836826347305389e-07,
        "rewards/chosen": -0.13974609971046448,
        "rewards/rejected": -0.37114256620407104,
        "rewards/accuracies": 0.6499999761581421,
        "rewards/margins": 0.23159585893154144,
        "logps/chosen": -233.35000610351562,
        "logps/rejected": -254.90834045410156,
        "logits/chosen": -0.807543933391571,
        "logits/rejected": -0.803417980670929,
        "epoch": 0.87,
        "step": 290
    },
    {
        "eval_loss": 0.5242773294448853,
        "eval_runtime": 8.3883,
        "eval_samples_per_second": 11.921,
        "eval_steps_per_second": 1.55,
        "eval_rewards/chosen": -0.21040226519107819,
        "eval_rewards/rejected": -0.6702223420143127,
        "eval_rewards/accuracies": 0.7884615659713745,
        "eval_rewards/margins": 0.4600736200809479,
        "eval_logps/chosen": -301.8846130371094,
        "eval_logps/rejected": -278.9615478515625,
        "eval_logits/chosen": -0.8849158883094788,
        "eval_logits/rejected": -0.9426081776618958,
        "epoch": 0.87,
        "step": 290
    },
    {
        "loss": 0.6241,
        "grad_norm": 112.21614837646484,
        "learning_rate": 2.7619760479041916e-07,
        "rewards/chosen": 0.03648274764418602,
        "rewards/rejected": -0.47822266817092896,
        "rewards/accuracies": 0.6166666746139526,
        "rewards/margins": 0.5142252445220947,
        "logps/chosen": -279.73333740234375,
        "logps/rejected": -293.29998779296875,
        "logits/chosen": -0.8003580570220947,
        "logits/rejected": -0.7914876341819763,
        "epoch": 0.9,
        "step": 300
    },
    {
        "eval_loss": 0.5278906226158142,
        "eval_runtime": 8.4128,
        "eval_samples_per_second": 11.887,
        "eval_steps_per_second": 1.545,
        "eval_rewards/chosen": -0.21397048234939575,
        "eval_rewards/rejected": -0.669921875,
        "eval_rewards/accuracies": 0.7788461446762085,
        "eval_rewards/margins": 0.45628005266189575,
        "eval_logps/chosen": -302.0384521484375,
        "eval_logps/rejected": -278.8461608886719,
        "eval_logits/chosen": -0.8891226053237915,
        "eval_logits/rejected": -0.9471153616905212,
        "epoch": 0.9,
        "step": 300
    },
    {
        "loss": 0.7955,
        "grad_norm": 82.41455078125,
        "learning_rate": 2.687125748502994e-07,
        "rewards/chosen": -0.03573404997587204,
        "rewards/rejected": -0.42849934101104736,
        "rewards/accuracies": 0.675000011920929,
        "rewards/margins": 0.39222005009651184,
        "logps/chosen": -319.4666748046875,
        "logps/rejected": -357.3999938964844,
        "logits/chosen": -0.769970715045929,
        "logits/rejected": -0.7930012941360474,
        "epoch": 0.93,
        "step": 310
    },
    {
        "eval_loss": 0.5200585722923279,
        "eval_runtime": 8.4039,
        "eval_samples_per_second": 11.899,
        "eval_steps_per_second": 1.547,
        "eval_rewards/chosen": -0.17893630266189575,
        "eval_rewards/rejected": -0.6624098420143127,
        "eval_rewards/accuracies": 0.7788461446762085,
        "eval_rewards/margins": 0.4833984375,
        "eval_logps/chosen": -301.4615478515625,
        "eval_logps/rejected": -278.8461608886719,
        "eval_logits/chosen": -0.8930288553237915,
        "eval_logits/rejected": -0.94921875,
        "epoch": 0.93,
        "step": 310
    },
    {
        "loss": 0.6551,
        "grad_norm": 156.6277313232422,
        "learning_rate": 2.612275449101796e-07,
        "rewards/chosen": -0.0661824569106102,
        "rewards/rejected": -0.4012084901332855,
        "rewards/accuracies": 0.6166666746139526,
        "rewards/margins": 0.3350016176700592,
        "logps/chosen": -240.9166717529297,
        "logps/rejected": -238.78334045410156,
        "logits/chosen": -0.765625,
        "logits/rejected": -0.7608886957168579,
        "epoch": 0.96,
        "step": 320
    },
    {
        "eval_loss": 0.5087695121765137,
        "eval_runtime": 8.4034,
        "eval_samples_per_second": 11.9,
        "eval_steps_per_second": 1.547,
        "eval_rewards/chosen": -0.15809044241905212,
        "eval_rewards/rejected": -0.673828125,
        "eval_rewards/accuracies": 0.7980769276618958,
        "eval_rewards/margins": 0.5160006284713745,
        "eval_logps/chosen": -301.19232177734375,
        "eval_logps/rejected": -278.8846130371094,
        "eval_logits/chosen": -0.89453125,
        "eval_logits/rejected": -0.9528245329856873,
        "epoch": 0.96,
        "step": 320
    },
    {
        "loss": 0.7132,
        "grad_norm": 62.546634674072266,
        "learning_rate": 2.537425149700599e-07,
        "rewards/chosen": 0.04118652269244194,
        "rewards/rejected": -0.42056477069854736,
        "rewards/accuracies": 0.625,
        "rewards/margins": 0.46170246601104736,
        "logps/chosen": -317.75,
        "logps/rejected": -283.70001220703125,
        "logits/chosen": -0.7690104246139526,
        "logits/rejected": -0.7815104126930237,
        "epoch": 0.99,
        "step": 330
    },
    {
        "eval_loss": 0.5102929472923279,
        "eval_runtime": 8.4241,
        "eval_samples_per_second": 11.871,
        "eval_steps_per_second": 1.543,
        "eval_rewards/chosen": -0.11170372366905212,
        "eval_rewards/rejected": -0.6326622366905212,
        "eval_rewards/accuracies": 0.7692307829856873,
        "eval_rewards/margins": 0.5209585428237915,
        "eval_logps/chosen": -301.0,
        "eval_logps/rejected": -278.6153869628906,
        "eval_logits/chosen": -0.8942307829856873,
        "eval_logits/rejected": -0.9516226053237915,
        "epoch": 0.99,
        "step": 330
    },
    {
        "loss": 0.562,
        "grad_norm": 76.1847915649414,
        "learning_rate": 2.4625748502994014e-07,
        "rewards/chosen": 0.2329275906085968,
        "rewards/rejected": -0.6077008843421936,
        "rewards/accuracies": 0.6875,
        "rewards/margins": 0.8396519422531128,
        "logps/chosen": -321.02679443359375,
        "logps/rejected": -296.0714416503906,
        "logits/chosen": -0.9005301594734192,
        "logits/rejected": -0.8449358344078064,
        "epoch": 1.018,
        "step": 340
    },
    {
        "eval_loss": 0.5101367235183716,
        "eval_runtime": 8.4082,
        "eval_samples_per_second": 11.893,
        "eval_steps_per_second": 1.546,
        "eval_rewards/chosen": -0.10201322287321091,
        "eval_rewards/rejected": -0.6256760954856873,
        "eval_rewards/accuracies": 0.7788461446762085,
        "eval_rewards/margins": 0.5224609375,
        "eval_logps/chosen": -301.1153869628906,
        "eval_logps/rejected": -278.5769348144531,
        "eval_logits/chosen": -0.8930288553237915,
        "eval_logits/rejected": -0.9498196840286255,
        "epoch": 1.018,
        "step": 340
    },
    {
        "loss": 0.5762,
        "grad_norm": 52.797637939453125,
        "learning_rate": 2.3877245508982035e-07,
        "rewards/chosen": 0.2911066710948944,
        "rewards/rejected": -0.5736328363418579,
        "rewards/accuracies": 0.7083333134651184,
        "rewards/margins": 0.8647623658180237,
        "logps/chosen": -221.39999389648438,
        "logps/rejected": -240.6999969482422,
        "logits/chosen": -0.8283040523529053,
        "logits/rejected": -0.7841145992279053,
        "epoch": 1.048,
        "step": 350
    },
    {
        "eval_loss": 0.5103320479393005,
        "eval_runtime": 8.4127,
        "eval_samples_per_second": 11.887,
        "eval_steps_per_second": 1.545,
        "eval_rewards/chosen": -0.05866417661309242,
        "eval_rewards/rejected": -0.5793269276618958,
        "eval_rewards/accuracies": 0.7692307829856873,
        "eval_rewards/margins": 0.5200570821762085,
        "eval_logps/chosen": -300.5769348144531,
        "eval_logps/rejected": -278.23077392578125,
        "eval_logits/chosen": -0.8948317170143127,
        "eval_logits/rejected": -0.9525240659713745,
        "epoch": 1.048,
        "step": 350
    },
    {
        "loss": 0.4791,
        "grad_norm": 40.04098129272461,
        "learning_rate": 2.3128742514970058e-07,
        "rewards/chosen": 0.7449869513511658,
        "rewards/rejected": -0.8493001461029053,
        "rewards/accuracies": 0.75,
        "rewards/margins": 1.593603491783142,
        "logps/chosen": -285.6166687011719,
        "logps/rejected": -268.01666259765625,
        "logits/chosen": -0.8221353888511658,
        "logits/rejected": -0.7849283814430237,
        "epoch": 1.078,
        "step": 360
    },
    {
        "eval_loss": 0.5120312571525574,
        "eval_runtime": 8.3909,
        "eval_samples_per_second": 11.918,
        "eval_steps_per_second": 1.549,
        "eval_rewards/chosen": 0.006920447573065758,
        "eval_rewards/rejected": -0.508864164352417,
        "eval_rewards/accuracies": 0.7596153616905212,
        "eval_rewards/margins": 0.515700101852417,
        "eval_logps/chosen": -299.9230651855469,
        "eval_logps/rejected": -277.4615478515625,
        "eval_logits/chosen": -0.8966346383094788,
        "eval_logits/rejected": -0.9543269276618958,
        "epoch": 1.078,
        "step": 360
    },
    {
        "loss": 0.5278,
        "grad_norm": 80.9285888671875,
        "learning_rate": 2.2380239520958082e-07,
        "rewards/chosen": 0.6332112550735474,
        "rewards/rejected": -0.7192057371139526,
        "rewards/accuracies": 0.6583333611488342,
        "rewards/margins": 1.3510620594024658,
        "logps/chosen": -290.5833435058594,
        "logps/rejected": -280.60833740234375,
        "logits/chosen": -0.8235026001930237,
        "logits/rejected": -0.802734375,
        "epoch": 1.108,
        "step": 370
    },
    {
        "eval_loss": 0.4996874928474426,
        "eval_runtime": 8.4122,
        "eval_samples_per_second": 11.888,
        "eval_steps_per_second": 1.545,
        "eval_rewards/chosen": 0.07292293012142181,
        "eval_rewards/rejected": -0.4833984375,
        "eval_rewards/accuracies": 0.7884615659713745,
        "eval_rewards/margins": 0.5560396909713745,
        "eval_logps/chosen": -299.5,
        "eval_logps/rejected": -277.1153869628906,
        "eval_logits/chosen": -0.8999398946762085,
        "eval_logits/rejected": -0.9564303159713745,
        "epoch": 1.108,
        "step": 370
    },
    {
        "loss": 0.5642,
        "grad_norm": 31.238304138183594,
        "learning_rate": 2.1631736526946108e-07,
        "rewards/chosen": 0.4425700008869171,
        "rewards/rejected": -0.7285318970680237,
        "rewards/accuracies": 0.7166666388511658,
        "rewards/margins": 1.1716145277023315,
        "logps/chosen": -312.375,
        "logps/rejected": -255.39999389648438,
        "logits/chosen": -0.9382161498069763,
        "logits/rejected": -0.8896809816360474,
        "epoch": 1.138,
        "step": 380
    },
    {
        "eval_loss": 0.5050195455551147,
        "eval_runtime": 8.4117,
        "eval_samples_per_second": 11.888,
        "eval_steps_per_second": 1.545,
        "eval_rewards/chosen": 0.05049955099821091,
        "eval_rewards/rejected": -0.4851825535297394,
        "eval_rewards/accuracies": 0.7884615659713745,
        "eval_rewards/margins": 0.536207914352417,
        "eval_logps/chosen": -299.4230651855469,
        "eval_logps/rejected": -277.1153869628906,
        "eval_logits/chosen": -0.8966346383094788,
        "eval_logits/rejected": -0.9552283883094788,
        "epoch": 1.138,
        "step": 380
    },
    {
        "loss": 0.6308,
        "grad_norm": 33.62281036376953,
        "learning_rate": 2.088323353293413e-07,
        "rewards/chosen": 0.4194936156272888,
        "rewards/rejected": -0.47032877802848816,
        "rewards/accuracies": 0.675000011920929,
        "rewards/margins": 0.890332043170929,
        "logps/chosen": -268.89166259765625,
        "logps/rejected": -234.85000610351562,
        "logits/chosen": -0.9152018427848816,
        "logits/rejected": -0.9229166507720947,
        "epoch": 1.168,
        "step": 390
    },
    {
        "eval_loss": 0.4984179735183716,
        "eval_runtime": 8.4099,
        "eval_samples_per_second": 11.891,
        "eval_steps_per_second": 1.546,
        "eval_rewards/chosen": 0.01968149095773697,
        "eval_rewards/rejected": -0.5450721383094788,
        "eval_rewards/accuracies": 0.7788461446762085,
        "eval_rewards/margins": 0.564453125,
        "eval_logps/chosen": -299.8461608886719,
        "eval_logps/rejected": -277.6153869628906,
        "eval_logits/chosen": -0.8963341116905212,
        "eval_logits/rejected": -0.9543269276618958,
        "epoch": 1.168,
        "step": 390
    },
    {
        "loss": 0.5983,
        "grad_norm": 21.788164138793945,
        "learning_rate": 2.0134730538922154e-07,
        "rewards/chosen": 0.4042317569255829,
        "rewards/rejected": -0.679882824420929,
        "rewards/accuracies": 0.7833333611488342,
        "rewards/margins": 1.0850911140441895,
        "logps/chosen": -290.5333251953125,
        "logps/rejected": -320.3500061035156,
        "logits/chosen": -0.8683431148529053,
        "logits/rejected": -0.8928385376930237,
        "epoch": 1.198,
        "step": 400
    },
    {
        "eval_loss": 0.49458983540534973,
        "eval_runtime": 8.4047,
        "eval_samples_per_second": 11.898,
        "eval_steps_per_second": 1.547,
        "eval_rewards/chosen": -0.08804086595773697,
        "eval_rewards/rejected": -0.6564002633094788,
        "eval_rewards/accuracies": 0.807692289352417,
        "eval_rewards/margins": 0.5687350034713745,
        "eval_logps/chosen": -300.8461608886719,
        "eval_logps/rejected": -278.76922607421875,
        "eval_logits/chosen": -0.9005408883094788,
        "eval_logits/rejected": -0.9573317170143127,
        "epoch": 1.198,
        "step": 400
    },
    {
        "loss": 0.5625,
        "grad_norm": 64.178466796875,
        "learning_rate": 1.9386227544910178e-07,
        "rewards/chosen": 0.27027180790901184,
        "rewards/rejected": -0.6826009154319763,
        "rewards/accuracies": 0.7333333492279053,
        "rewards/margins": 0.9532063603401184,
        "logps/chosen": -224.7083282470703,
        "logps/rejected": -205.0416717529297,
        "logits/chosen": -0.794921875,
        "logits/rejected": -0.7551432251930237,
        "epoch": 1.228,
        "step": 410
    },
    {
        "eval_loss": 0.4940429627895355,
        "eval_runtime": 8.4012,
        "eval_samples_per_second": 11.903,
        "eval_steps_per_second": 1.547,
        "eval_rewards/chosen": -0.08242563158273697,
        "eval_rewards/rejected": -0.6588040590286255,
        "eval_rewards/accuracies": 0.7692307829856873,
        "eval_rewards/margins": 0.5757962465286255,
        "eval_logps/chosen": -300.69232177734375,
        "eval_logps/rejected": -278.8461608886719,
        "eval_logits/chosen": -0.90234375,
        "eval_logits/rejected": -0.9588341116905212,
        "epoch": 1.228,
        "step": 410
    },
    {
        "loss": 0.6817,
        "grad_norm": 78.04574584960938,
        "learning_rate": 1.8637724550898204e-07,
        "rewards/chosen": 0.43828123807907104,
        "rewards/rejected": -0.7491292357444763,
        "rewards/accuracies": 0.7583333253860474,
        "rewards/margins": 1.186132788658142,
        "logps/chosen": -288.1166687011719,
        "logps/rejected": -284.2250061035156,
        "logits/chosen": -0.823437511920929,
        "logits/rejected": -0.7800374627113342,
        "epoch": 1.258,
        "step": 420
    },
    {
        "eval_loss": 0.48341795802116394,
        "eval_runtime": 8.4172,
        "eval_samples_per_second": 11.88,
        "eval_steps_per_second": 1.544,
        "eval_rewards/chosen": -0.050518330186605453,
        "eval_rewards/rejected": -0.6656399965286255,
        "eval_rewards/accuracies": 0.7596153616905212,
        "eval_rewards/margins": 0.6144831776618958,
        "eval_logps/chosen": -300.3461608886719,
        "eval_logps/rejected": -278.8461608886719,
        "eval_logits/chosen": -0.903245210647583,
        "eval_logits/rejected": -0.9612379670143127,
        "epoch": 1.258,
        "step": 420
    },
    {
        "loss": 0.5011,
        "grad_norm": 20.458621978759766,
        "learning_rate": 1.7889221556886227e-07,
        "rewards/chosen": 0.40495604276657104,
        "rewards/rejected": -0.7677409052848816,
        "rewards/accuracies": 0.6833333373069763,
        "rewards/margins": 1.1719400882720947,
        "logps/chosen": -266.3500061035156,
        "logps/rejected": -243.47500610351562,
        "logits/chosen": -0.8957682251930237,
        "logits/rejected": -0.8737467527389526,
        "epoch": 1.288,
        "step": 430
    },
    {
        "eval_loss": 0.48511719703674316,
        "eval_runtime": 8.4096,
        "eval_samples_per_second": 11.891,
        "eval_steps_per_second": 1.546,
        "eval_rewards/chosen": 0.027303842827677727,
        "eval_rewards/rejected": -0.5857496857643127,
        "eval_rewards/accuracies": 0.7692307829856873,
        "eval_rewards/margins": 0.6131309866905212,
        "eval_logps/chosen": -299.6153869628906,
        "eval_logps/rejected": -278.0384521484375,
        "eval_logits/chosen": -0.9020432829856873,
        "eval_logits/rejected": -0.9588341116905212,
        "epoch": 1.288,
        "step": 430
    },
    {
        "loss": 0.4122,
        "grad_norm": 20.048931121826172,
        "learning_rate": 1.714071856287425e-07,
        "rewards/chosen": 0.6774984002113342,
        "rewards/rejected": -0.8710774779319763,
        "rewards/accuracies": 0.800000011920929,
        "rewards/margins": 1.5505859851837158,
        "logps/chosen": -248.73333740234375,
        "logps/rejected": -224.86666870117188,
        "logits/chosen": -0.7874837517738342,
        "logits/rejected": -0.7934407591819763,
        "epoch": 1.318,
        "step": 440
    },
    {
        "eval_loss": 0.48435547947883606,
        "eval_runtime": 8.4166,
        "eval_samples_per_second": 11.881,
        "eval_steps_per_second": 1.545,
        "eval_rewards/chosen": 0.10021033883094788,
        "eval_rewards/rejected": -0.5369873046875,
        "eval_rewards/accuracies": 0.7596153616905212,
        "eval_rewards/margins": 0.636793851852417,
        "eval_logps/chosen": -299.30767822265625,
        "eval_logps/rejected": -277.6538391113281,
        "eval_logits/chosen": -0.9017428159713745,
        "eval_logits/rejected": -0.9591346383094788,
        "epoch": 1.318,
        "step": 440
    },
    {
        "loss": 0.5679,
        "grad_norm": 62.822601318359375,
        "learning_rate": 1.6392215568862276e-07,
        "rewards/chosen": 0.4697916805744171,
        "rewards/rejected": -0.6489420533180237,
        "rewards/accuracies": 0.6499999761581421,
        "rewards/margins": 1.1182372570037842,
        "logps/chosen": -260.5333251953125,
        "logps/rejected": -263.3666687011719,
        "logits/chosen": -0.8656982183456421,
        "logits/rejected": -0.8638671636581421,
        "epoch": 1.3479999999999999,
        "step": 450
    },
    {
        "eval_loss": 0.4725683629512787,
        "eval_runtime": 8.4156,
        "eval_samples_per_second": 11.883,
        "eval_steps_per_second": 1.545,
        "eval_rewards/chosen": 0.14690692722797394,
        "eval_rewards/rejected": -0.550706148147583,
        "eval_rewards/accuracies": 0.7884615659713745,
        "eval_rewards/margins": 0.6971153616905212,
        "eval_logps/chosen": -298.5769348144531,
        "eval_logps/rejected": -277.8846130371094,
        "eval_logits/chosen": -0.903245210647583,
        "eval_logits/rejected": -0.9606370329856873,
        "epoch": 1.3479999999999999,
        "step": 450
    },
    {
        "loss": 0.4508,
        "grad_norm": 61.02091598510742,
        "learning_rate": 1.56437125748503e-07,
        "rewards/chosen": 0.6808003783226013,
        "rewards/rejected": -0.6548665165901184,
        "rewards/accuracies": 0.7333333492279053,
        "rewards/margins": 1.3347331285476685,
        "logps/chosen": -267.54998779296875,
        "logps/rejected": -243.75,
        "logits/chosen": -0.8649495244026184,
        "logits/rejected": -0.8055094480514526,
        "epoch": 1.3780000000000001,
        "step": 460
    },
    {
        "eval_loss": 0.46558594703674316,
        "eval_runtime": 8.4062,
        "eval_samples_per_second": 11.896,
        "eval_steps_per_second": 1.546,
        "eval_rewards/chosen": 0.07222806662321091,
        "eval_rewards/rejected": -0.635847806930542,
        "eval_rewards/accuracies": 0.7788461446762085,
        "eval_rewards/margins": 0.7078575491905212,
        "eval_logps/chosen": -299.3846130371094,
        "eval_logps/rejected": -278.4230651855469,
        "eval_logits/chosen": -0.9038461446762085,
        "eval_logits/rejected": -0.9627403616905212,
        "epoch": 1.3780000000000001,
        "step": 460
    },
    {
        "loss": 0.4665,
        "grad_norm": 37.83346176147461,
        "learning_rate": 1.4895209580838323e-07,
        "rewards/chosen": 0.6854003667831421,
        "rewards/rejected": -1.0108236074447632,
        "rewards/accuracies": 0.7333333492279053,
        "rewards/margins": 1.6945312023162842,
        "logps/chosen": -219.60833740234375,
        "logps/rejected": -212.6999969482422,
        "logits/chosen": -0.804882824420929,
        "logits/rejected": -0.816210925579071,
        "epoch": 1.408,
        "step": 470
    },
    {
        "eval_loss": 0.4562304615974426,
        "eval_runtime": 8.3923,
        "eval_samples_per_second": 11.916,
        "eval_steps_per_second": 1.549,
        "eval_rewards/chosen": -0.010178785771131516,
        "eval_rewards/rejected": -0.7642728090286255,
        "eval_rewards/accuracies": 0.7692307829856873,
        "eval_rewards/margins": 0.75390625,
        "eval_logps/chosen": -299.8846130371094,
        "eval_logps/rejected": -280.1153869628906,
        "eval_logits/chosen": -0.9074519276618958,
        "eval_logits/rejected": -0.9660456776618958,
        "epoch": 1.408,
        "step": 470
    },
    {
        "loss": 0.6473,
        "grad_norm": 49.899085998535156,
        "learning_rate": 1.4146706586826346e-07,
        "rewards/chosen": 0.28828126192092896,
        "rewards/rejected": -0.6362141966819763,
        "rewards/accuracies": 0.675000011920929,
        "rewards/margins": 0.9246907830238342,
        "logps/chosen": -249.11666870117188,
        "logps/rejected": -269.26666259765625,
        "logits/chosen": -0.7781575322151184,
        "logits/rejected": -0.7718424201011658,
        "epoch": 1.438,
        "step": 480
    },
    {
        "eval_loss": 0.45804688334465027,
        "eval_runtime": 8.4053,
        "eval_samples_per_second": 11.897,
        "eval_steps_per_second": 1.547,
        "eval_rewards/chosen": -0.12031437456607819,
        "eval_rewards/rejected": -0.8668870329856873,
        "eval_rewards/accuracies": 0.7980769276618958,
        "eval_rewards/margins": 0.746168851852417,
        "eval_logps/chosen": -301.0769348144531,
        "eval_logps/rejected": -281.0,
        "eval_logits/chosen": -0.9083533883094788,
        "eval_logits/rejected": -0.967848539352417,
        "epoch": 1.438,
        "step": 480
    },
    {
        "loss": 0.3899,
        "grad_norm": 22.435956954956055,
        "learning_rate": 1.339820359281437e-07,
        "rewards/chosen": 0.6141275763511658,
        "rewards/rejected": -1.277441382408142,
        "rewards/accuracies": 0.7916666865348816,
        "rewards/margins": 1.8925455808639526,
        "logps/chosen": -306.8333435058594,
        "logps/rejected": -298.9666748046875,
        "logits/chosen": -0.827075183391571,
        "logits/rejected": -0.8346842527389526,
        "epoch": 1.468,
        "step": 490
    },
    {
        "eval_loss": 0.4530078172683716,
        "eval_runtime": 8.4083,
        "eval_samples_per_second": 11.893,
        "eval_steps_per_second": 1.546,
        "eval_rewards/chosen": -0.08710186183452606,
        "eval_rewards/rejected": -0.8637319803237915,
        "eval_rewards/accuracies": 0.7980769276618958,
        "eval_rewards/margins": 0.7768930196762085,
        "eval_logps/chosen": -300.8461608886719,
        "eval_logps/rejected": -281.0,
        "eval_logits/chosen": -0.907151460647583,
        "eval_logits/rejected": -0.9663461446762085,
        "epoch": 1.468,
        "step": 490
    },
    {
        "loss": 0.4772,
        "grad_norm": 26.453031539916992,
        "learning_rate": 1.2649700598802395e-07,
        "rewards/chosen": 0.3769938051700592,
        "rewards/rejected": -1.1646809577941895,
        "rewards/accuracies": 0.7416666746139526,
        "rewards/margins": 1.5403646230697632,
        "logps/chosen": -234.4583282470703,
        "logps/rejected": -265.92498779296875,
        "logits/chosen": -0.7396810054779053,
        "logits/rejected": -0.7542887330055237,
        "epoch": 1.498,
        "step": 500
    },
    {
        "eval_loss": 0.4434863328933716,
        "eval_runtime": 8.399,
        "eval_samples_per_second": 11.906,
        "eval_steps_per_second": 1.548,
        "eval_rewards/chosen": -0.005108173005282879,
        "eval_rewards/rejected": -0.829176664352417,
        "eval_rewards/accuracies": 0.7980769276618958,
        "eval_rewards/margins": 0.8249699473381042,
        "eval_logps/chosen": -300.0,
        "eval_logps/rejected": -280.69232177734375,
        "eval_logits/chosen": -0.9083533883094788,
        "eval_logits/rejected": -0.9684495329856873,
        "epoch": 1.498,
        "step": 500
    },
    {
        "loss": 0.5766,
        "grad_norm": 87.30755615234375,
        "learning_rate": 1.1901197604790419e-07,
        "rewards/chosen": 0.4410807192325592,
        "rewards/rejected": -0.8436197638511658,
        "rewards/accuracies": 0.675000011920929,
        "rewards/margins": 1.2852274179458618,
        "logps/chosen": -224.61666870117188,
        "logps/rejected": -287.7416687011719,
        "logits/chosen": -0.8479817509651184,
        "logits/rejected": -0.8504231572151184,
        "epoch": 1.528,
        "step": 510
    },
    {
        "eval_loss": 0.4483984410762787,
        "eval_runtime": 8.3985,
        "eval_samples_per_second": 11.907,
        "eval_steps_per_second": 1.548,
        "eval_rewards/chosen": 0.09986290335655212,
        "eval_rewards/rejected": -0.7092097401618958,
        "eval_rewards/accuracies": 0.807692289352417,
        "eval_rewards/margins": 0.80859375,
        "eval_logps/chosen": -299.0384521484375,
        "eval_logps/rejected": -279.3461608886719,
        "eval_logits/chosen": -0.9086538553237915,
        "eval_logits/rejected": -0.9681490659713745,
        "epoch": 1.528,
        "step": 510
    },
    {
        "loss": 0.5357,
        "grad_norm": 65.2916488647461,
        "learning_rate": 1.1152694610778443e-07,
        "rewards/chosen": 0.536450207233429,
        "rewards/rejected": -0.69110107421875,
        "rewards/accuracies": 0.6499999761581421,
        "rewards/margins": 1.2268555164337158,
        "logps/chosen": -311.1916809082031,
        "logps/rejected": -269.9416809082031,
        "logits/chosen": -0.8335937261581421,
        "logits/rejected": -0.8232747316360474,
        "epoch": 1.558,
        "step": 520
    },
    {
        "eval_loss": 0.453857421875,
        "eval_runtime": 8.3893,
        "eval_samples_per_second": 11.92,
        "eval_steps_per_second": 1.55,
        "eval_rewards/chosen": 0.19003531336784363,
        "eval_rewards/rejected": -0.6129525899887085,
        "eval_rewards/accuracies": 0.7788461446762085,
        "eval_rewards/margins": 0.802734375,
        "eval_logps/chosen": -298.23077392578125,
        "eval_logps/rejected": -278.5,
        "eval_logits/chosen": -0.9107571840286255,
        "eval_logits/rejected": -0.96875,
        "epoch": 1.558,
        "step": 520
    },
    {
        "loss": 0.699,
        "grad_norm": 10.349939346313477,
        "learning_rate": 1.0404191616766467e-07,
        "rewards/chosen": 0.4241780638694763,
        "rewards/rejected": -0.6998046636581421,
        "rewards/accuracies": 0.675000011920929,
        "rewards/margins": 1.1229166984558105,
        "logps/chosen": -262.5833435058594,
        "logps/rejected": -301.54998779296875,
        "logits/chosen": -0.7575846314430237,
        "logits/rejected": -0.8315104246139526,
        "epoch": 1.588,
        "step": 530
    },
    {
        "eval_loss": 0.45054686069488525,
        "eval_runtime": 8.3894,
        "eval_samples_per_second": 11.92,
        "eval_steps_per_second": 1.55,
        "eval_rewards/chosen": 0.14259690046310425,
        "eval_rewards/rejected": -0.6700721383094788,
        "eval_rewards/accuracies": 0.7788461446762085,
        "eval_rewards/margins": 0.8125,
        "eval_logps/chosen": -298.69232177734375,
        "eval_logps/rejected": -278.9230651855469,
        "eval_logits/chosen": -0.9119591116905212,
        "eval_logits/rejected": -0.9705528616905212,
        "epoch": 1.588,
        "step": 530
    },
    {
        "loss": 0.4906,
        "grad_norm": 84.7306137084961,
        "learning_rate": 9.65568862275449e-08,
        "rewards/chosen": 0.7291829586029053,
        "rewards/rejected": -0.7245523929595947,
        "rewards/accuracies": 0.699999988079071,
        "rewards/margins": 1.454492211341858,
        "logps/chosen": -234.97500610351562,
        "logps/rejected": -277.125,
        "logits/chosen": -0.8404296636581421,
        "logits/rejected": -0.852343738079071,
        "epoch": 1.6179999999999999,
        "step": 540
    },
    {
        "eval_loss": 0.44896483421325684,
        "eval_runtime": 8.3948,
        "eval_samples_per_second": 11.912,
        "eval_steps_per_second": 1.549,
        "eval_rewards/chosen": 0.13766714930534363,
        "eval_rewards/rejected": -0.674241304397583,
        "eval_rewards/accuracies": 0.807692289352417,
        "eval_rewards/margins": 0.8116737008094788,
        "eval_logps/chosen": -298.76922607421875,
        "eval_logps/rejected": -278.9230651855469,
        "eval_logits/chosen": -0.9122596383094788,
        "eval_logits/rejected": -0.9708533883094788,
        "epoch": 1.6179999999999999,
        "step": 540
    },
    {
        "loss": 0.5657,
        "grad_norm": 106.16470336914062,
        "learning_rate": 8.907185628742514e-08,
        "rewards/chosen": 0.7714273929595947,
        "rewards/rejected": -0.7392252683639526,
        "rewards/accuracies": 0.7416666746139526,
        "rewards/margins": 1.5115071535110474,
        "logps/chosen": -335.9333190917969,
        "logps/rejected": -297.2250061035156,
        "logits/chosen": -0.900195300579071,
        "logits/rejected": -0.9033203125,
        "epoch": 1.6480000000000001,
        "step": 550
    },
    {
        "eval_loss": 0.45320311188697815,
        "eval_runtime": 8.3936,
        "eval_samples_per_second": 11.914,
        "eval_steps_per_second": 1.549,
        "eval_rewards/chosen": 0.19142502546310425,
        "eval_rewards/rejected": -0.6044921875,
        "eval_rewards/accuracies": 0.7884615659713745,
        "eval_rewards/margins": 0.7956730723381042,
        "eval_logps/chosen": -298.0384521484375,
        "eval_logps/rejected": -278.6538391113281,
        "eval_logits/chosen": -0.9119591116905212,
        "eval_logits/rejected": -0.9699519276618958,
        "epoch": 1.6480000000000001,
        "step": 550
    },
    {
        "loss": 0.4555,
        "grad_norm": 83.22291564941406,
        "learning_rate": 8.158682634730539e-08,
        "rewards/chosen": 0.8527018427848816,
        "rewards/rejected": -0.7820637822151184,
        "rewards/accuracies": 0.7583333253860474,
        "rewards/margins": 1.636328101158142,
        "logps/chosen": -288.5416564941406,
        "logps/rejected": -250.98333740234375,
        "logits/chosen": -0.8907552361488342,
        "logits/rejected": -0.8752278685569763,
        "epoch": 1.678,
        "step": 560
    },
    {
        "eval_loss": 0.4590136706829071,
        "eval_runtime": 8.3856,
        "eval_samples_per_second": 11.925,
        "eval_steps_per_second": 1.55,
        "eval_rewards/chosen": 0.27593994140625,
        "eval_rewards/rejected": -0.5076810121536255,
        "eval_rewards/accuracies": 0.7788461446762085,
        "eval_rewards/margins": 0.7835787534713745,
        "eval_logps/chosen": -297.0,
        "eval_logps/rejected": -277.30767822265625,
        "eval_logits/chosen": -0.913161039352417,
        "eval_logits/rejected": -0.9699519276618958,
        "epoch": 1.678,
        "step": 560
    },
    {
        "loss": 0.5943,
        "grad_norm": 175.16404724121094,
        "learning_rate": 7.410179640718562e-08,
        "rewards/chosen": 0.78125,
        "rewards/rejected": -0.8948567509651184,
        "rewards/accuracies": 0.7250000238418579,
        "rewards/margins": 1.6770508289337158,
        "logps/chosen": -290.4666748046875,
        "logps/rejected": -296.2166748046875,
        "logits/chosen": -0.912890613079071,
        "logits/rejected": -0.885937511920929,
        "epoch": 1.708,
        "step": 570
    },
    {
        "eval_loss": 0.4525683522224426,
        "eval_runtime": 8.4046,
        "eval_samples_per_second": 11.898,
        "eval_steps_per_second": 1.547,
        "eval_rewards/chosen": 0.3023775517940521,
        "eval_rewards/rejected": -0.4925630986690521,
        "eval_rewards/accuracies": 0.7596153616905212,
        "eval_rewards/margins": 0.7946214079856873,
        "eval_logps/chosen": -296.8461608886719,
        "eval_logps/rejected": -277.0384521484375,
        "eval_logits/chosen": -0.9137620329856873,
        "eval_logits/rejected": -0.9708533883094788,
        "epoch": 1.708,
        "step": 570
    },
    {
        "loss": 0.5079,
        "grad_norm": 63.54230499267578,
        "learning_rate": 6.661676646706586e-08,
        "rewards/chosen": 0.9790689945220947,
        "rewards/rejected": -0.8107991814613342,
        "rewards/accuracies": 0.7416666746139526,
        "rewards/margins": 1.7880208492279053,
        "logps/chosen": -246.0500030517578,
        "logps/rejected": -255.2083282470703,
        "logits/chosen": -0.8317301273345947,
        "logits/rejected": -0.7740071415901184,
        "epoch": 1.738,
        "step": 580
    },
    {
        "eval_loss": 0.45341795682907104,
        "eval_runtime": 8.4213,
        "eval_samples_per_second": 11.875,
        "eval_steps_per_second": 1.544,
        "eval_rewards/chosen": 0.2520845830440521,
        "eval_rewards/rejected": -0.5566781759262085,
        "eval_rewards/accuracies": 0.7692307829856873,
        "eval_rewards/margins": 0.8081430196762085,
        "eval_logps/chosen": -297.4615478515625,
        "eval_logps/rejected": -277.80767822265625,
        "eval_logits/chosen": -0.9137620329856873,
        "eval_logits/rejected": -0.9720553159713745,
        "epoch": 1.738,
        "step": 580
    },
    {
        "loss": 0.4838,
        "grad_norm": 114.31177520751953,
        "learning_rate": 5.9131736526946103e-08,
        "rewards/chosen": 0.7826985716819763,
        "rewards/rejected": -0.7249348759651184,
        "rewards/accuracies": 0.7749999761581421,
        "rewards/margins": 1.5082844495773315,
        "logps/chosen": -292.0208435058594,
        "logps/rejected": -244.49166870117188,
        "logits/chosen": -0.8963541388511658,
        "logits/rejected": -0.8809570074081421,
        "epoch": 1.768,
        "step": 590
    },
    {
        "eval_loss": 0.45945313572883606,
        "eval_runtime": 8.4165,
        "eval_samples_per_second": 11.881,
        "eval_steps_per_second": 1.545,
        "eval_rewards/chosen": 0.2296518236398697,
        "eval_rewards/rejected": -0.5691856741905212,
        "eval_rewards/accuracies": 0.7596153616905212,
        "eval_rewards/margins": 0.7991285920143127,
        "eval_logps/chosen": -297.80767822265625,
        "eval_logps/rejected": -277.9615478515625,
        "eval_logits/chosen": -0.9140625,
        "eval_logits/rejected": -0.971754789352417,
        "epoch": 1.768,
        "step": 590
    },
    {
        "loss": 0.474,
        "grad_norm": 29.833311080932617,
        "learning_rate": 5.164670658682634e-08,
        "rewards/chosen": 0.8710774779319763,
        "rewards/rejected": -0.6087728142738342,
        "rewards/accuracies": 0.7749999761581421,
        "rewards/margins": 1.4796549081802368,
        "logps/chosen": -255.06666564941406,
        "logps/rejected": -264.8333435058594,
        "logits/chosen": -0.8192057013511658,
        "logits/rejected": -0.8153320550918579,
        "epoch": 1.798,
        "step": 600
    },
    {
        "eval_loss": 0.4458886682987213,
        "eval_runtime": 8.4205,
        "eval_samples_per_second": 11.876,
        "eval_steps_per_second": 1.544,
        "eval_rewards/chosen": 0.25445085763931274,
        "eval_rewards/rejected": -0.5750145316123962,
        "eval_rewards/accuracies": 0.7692307829856873,
        "eval_rewards/margins": 0.8297776579856873,
        "eval_logps/chosen": -297.5384521484375,
        "eval_logps/rejected": -278.23077392578125,
        "eval_logits/chosen": -0.9143629670143127,
        "eval_logits/rejected": -0.9720553159713745,
        "epoch": 1.798,
        "step": 600
    },
    {
        "loss": 0.4573,
        "grad_norm": 32.806602478027344,
        "learning_rate": 4.416167664670658e-08,
        "rewards/chosen": 1.0546224117279053,
        "rewards/rejected": -0.687939465045929,
        "rewards/accuracies": 0.7666666507720947,
        "rewards/margins": 1.7412109375,
        "logps/chosen": -259.0666809082031,
        "logps/rejected": -322.6000061035156,
        "logits/chosen": -0.9267578125,
        "logits/rejected": -0.8677083253860474,
        "epoch": 1.8279999999999998,
        "step": 610
    },
    {
        "eval_loss": 0.4560839831829071,
        "eval_runtime": 8.4109,
        "eval_samples_per_second": 11.889,
        "eval_steps_per_second": 1.546,
        "eval_rewards/chosen": 0.2805927097797394,
        "eval_rewards/rejected": -0.507981538772583,
        "eval_rewards/accuracies": 0.7596153616905212,
        "eval_rewards/margins": 0.788987398147583,
        "eval_logps/chosen": -296.9230651855469,
        "eval_logps/rejected": -277.19232177734375,
        "eval_logits/chosen": -0.9137620329856873,
        "eval_logits/rejected": -0.9714543223381042,
        "epoch": 1.8279999999999998,
        "step": 610
    },
    {
        "loss": 0.4424,
        "grad_norm": 58.811492919921875,
        "learning_rate": 3.667664670658682e-08,
        "rewards/chosen": 0.8230305910110474,
        "rewards/rejected": -0.8613199591636658,
        "rewards/accuracies": 0.8166666626930237,
        "rewards/margins": 1.6857095956802368,
        "logps/chosen": -246.00833129882812,
        "logps/rejected": -278.4666748046875,
        "logits/chosen": -0.8435872197151184,
        "logits/rejected": -0.8509114384651184,
        "epoch": 1.858,
        "step": 620
    },
    {
        "eval_loss": 0.44775390625,
        "eval_runtime": 8.4146,
        "eval_samples_per_second": 11.884,
        "eval_steps_per_second": 1.545,
        "eval_rewards/chosen": 0.3080303370952606,
        "eval_rewards/rejected": -0.5108079314231873,
        "eval_rewards/accuracies": 0.7884615659713745,
        "eval_rewards/margins": 0.818359375,
        "eval_logps/chosen": -296.9615478515625,
        "eval_logps/rejected": -277.3846130371094,
        "eval_logits/chosen": -0.9146634340286255,
        "eval_logits/rejected": -0.97265625,
        "epoch": 1.858,
        "step": 620
    },
    {
        "loss": 0.5029,
        "grad_norm": 20.235782623291016,
        "learning_rate": 2.9191616766467065e-08,
        "rewards/chosen": 0.7679768800735474,
        "rewards/rejected": -0.6430338621139526,
        "rewards/accuracies": 0.7333333492279053,
        "rewards/margins": 1.4098632335662842,
        "logps/chosen": -234.0833282470703,
        "logps/rejected": -251.51666259765625,
        "logits/chosen": -0.843554675579071,
        "logits/rejected": -0.8084309697151184,
        "epoch": 1.888,
        "step": 630
    },
    {
        "eval_loss": 0.45341795682907104,
        "eval_runtime": 8.4147,
        "eval_samples_per_second": 11.884,
        "eval_steps_per_second": 1.545,
        "eval_rewards/chosen": 0.3331204950809479,
        "eval_rewards/rejected": -0.47219613194465637,
        "eval_rewards/accuracies": 0.7692307829856873,
        "eval_rewards/margins": 0.8061898946762085,
        "eval_logps/chosen": -296.5769348144531,
        "eval_logps/rejected": -277.1153869628906,
        "eval_logits/chosen": -0.9140625,
        "eval_logits/rejected": -0.9720553159713745,
        "epoch": 1.888,
        "step": 630
    },
    {
        "loss": 0.624,
        "grad_norm": 115.75442504882812,
        "learning_rate": 2.1706586826347305e-08,
        "rewards/chosen": 0.696826159954071,
        "rewards/rejected": -0.7307454347610474,
        "rewards/accuracies": 0.7083333134651184,
        "rewards/margins": 1.4278970956802368,
        "logps/chosen": -389.4916687011719,
        "logps/rejected": -292.01666259765625,
        "logits/chosen": -0.8259114623069763,
        "logits/rejected": -0.866381824016571,
        "epoch": 1.9180000000000001,
        "step": 640
    },
    {
        "eval_loss": 0.455322265625,
        "eval_runtime": 8.404,
        "eval_samples_per_second": 11.899,
        "eval_steps_per_second": 1.547,
        "eval_rewards/chosen": 0.3292142450809479,
        "eval_rewards/rejected": -0.47720101475715637,
        "eval_rewards/accuracies": 0.75,
        "eval_rewards/margins": 0.806640625,
        "eval_logps/chosen": -296.4230651855469,
        "eval_logps/rejected": -277.1538391113281,
        "eval_logits/chosen": -0.9140625,
        "eval_logits/rejected": -0.9729567170143127,
        "epoch": 1.9180000000000001,
        "step": 640
    },
    {
        "loss": 0.5017,
        "grad_norm": 61.049949645996094,
        "learning_rate": 1.4221556886227543e-08,
        "rewards/chosen": 0.8023274540901184,
        "rewards/rejected": -0.39779460430145264,
        "rewards/accuracies": 0.7083333134651184,
        "rewards/margins": 1.199316382408142,
        "logps/chosen": -292.8666687011719,
        "logps/rejected": -269.8333435058594,
        "logits/chosen": -0.7933267951011658,
        "logits/rejected": -0.7755208611488342,
        "epoch": 1.948,
        "step": 650
    },
    {
        "eval_loss": 0.4493164122104645,
        "eval_runtime": 8.4293,
        "eval_samples_per_second": 11.863,
        "eval_steps_per_second": 1.542,
        "eval_rewards/chosen": 0.3158052861690521,
        "eval_rewards/rejected": -0.504441499710083,
        "eval_rewards/accuracies": 0.7788461446762085,
        "eval_rewards/margins": 0.821364164352417,
        "eval_logps/chosen": -296.80767822265625,
        "eval_logps/rejected": -277.1538391113281,
        "eval_logits/chosen": -0.9134615659713745,
        "eval_logits/rejected": -0.9723557829856873,
        "epoch": 1.948,
        "step": 650
    },
    {
        "loss": 0.4849,
        "grad_norm": 7.104567527770996,
        "learning_rate": 6.736526946107784e-09,
        "rewards/chosen": 0.9537190794944763,
        "rewards/rejected": -0.5947916507720947,
        "rewards/accuracies": 0.75,
        "rewards/margins": 1.548730492591858,
        "logps/chosen": -316.13751220703125,
        "logps/rejected": -254.69166564941406,
        "logits/chosen": -0.7866861820220947,
        "logits/rejected": -0.760693371295929,
        "epoch": 1.978,
        "step": 660
    },
    {
        "eval_loss": 0.45357421040534973,
        "eval_runtime": 8.3997,
        "eval_samples_per_second": 11.905,
        "eval_steps_per_second": 1.548,
        "eval_rewards/chosen": 0.3039456903934479,
        "eval_rewards/rejected": -0.50970458984375,
        "eval_rewards/accuracies": 0.7884615659713745,
        "eval_rewards/margins": 0.8138521909713745,
        "eval_logps/chosen": -296.80767822265625,
        "eval_logps/rejected": -277.3846130371094,
        "eval_logits/chosen": -0.9143629670143127,
        "eval_logits/rejected": -0.97265625,
        "epoch": 1.978,
        "step": 660
    },
    {
        "train_runtime": 4587.9867,
        "train_samples_per_second": 1.744,
        "train_steps_per_second": 0.146,
        "total_flos": 0.0,
        "train_loss": 0.6099160766887094,
        "epoch": 2.0,
        "step": 668
    }
]