[
    {
        "loss": 0.6815,
        "grad_norm": 55.607749938964844,
        "learning_rate": 4.865269461077843e-07,
        "rewards/chosen": 0.021545665338635445,
        "rewards/rejected": -0.0052164713852107525,
        "rewards/accuracies": 0.3916666805744171,
        "rewards/margins": 0.02674814872443676,
        "logps/chosen": -243.93333435058594,
        "logps/rejected": -216.4583282470703,
        "logits/chosen": -0.7306233644485474,
        "logits/rejected": -0.7057454586029053,
        "epoch": 0.06,
        "step": 10
    },
    {
        "eval_loss": 0.7032031416893005,
        "eval_runtime": 8.3491,
        "eval_samples_per_second": 11.977,
        "eval_steps_per_second": 1.557,
        "eval_rewards/chosen": 0.02508310228586197,
        "eval_rewards/rejected": 0.03403649106621742,
        "eval_rewards/accuracies": 0.3365384638309479,
        "eval_rewards/margins": -0.008857140317559242,
        "eval_logps/chosen": -299.9230651855469,
        "eval_logps/rejected": -271.9615478515625,
        "eval_logits/chosen": -0.8239182829856873,
        "eval_logits/rejected": -0.8843148946762085,
        "epoch": 0.06,
        "step": 10
    },
    {
        "loss": 0.687,
        "grad_norm": 64.87458038330078,
        "learning_rate": 4.715568862275449e-07,
        "rewards/chosen": 0.03848164901137352,
        "rewards/rejected": 0.01897074468433857,
        "rewards/accuracies": 0.36666667461395264,
        "rewards/margins": 0.01950022391974926,
        "logps/chosen": -301.51251220703125,
        "logps/rejected": -254.30833435058594,
        "logits/chosen": -0.7648112177848816,
        "logits/rejected": -0.7092122435569763,
        "epoch": 0.12,
        "step": 20
    },
    {
        "eval_loss": 0.6946874856948853,
        "eval_runtime": 8.3678,
        "eval_samples_per_second": 11.951,
        "eval_steps_per_second": 1.554,
        "eval_rewards/chosen": 0.06670673191547394,
        "eval_rewards/rejected": 0.06316199898719788,
        "eval_rewards/accuracies": 0.42307692766189575,
        "eval_rewards/margins": 0.003523606574162841,
        "eval_logps/chosen": -299.19232177734375,
        "eval_logps/rejected": -271.80767822265625,
        "eval_logits/chosen": -0.8239182829856873,
        "eval_logits/rejected": -0.8840144276618958,
        "epoch": 0.12,
        "step": 20
    },
    {
        "loss": 0.6873,
        "grad_norm": 247.23939514160156,
        "learning_rate": 4.565868263473054e-07,
        "rewards/chosen": 0.08123169094324112,
        "rewards/rejected": 0.06440836936235428,
        "rewards/accuracies": 0.42500001192092896,
        "rewards/margins": 0.01682332344353199,
        "logps/chosen": -263.8416748046875,
        "logps/rejected": -247.39999389648438,
        "logits/chosen": -0.7167806029319763,
        "logits/rejected": -0.7106851935386658,
        "epoch": 0.18,
        "step": 30
    },
    {
        "eval_loss": 0.6776562333106995,
        "eval_runtime": 8.3858,
        "eval_samples_per_second": 11.925,
        "eval_steps_per_second": 1.55,
        "eval_rewards/chosen": 0.11745042353868484,
        "eval_rewards/rejected": 0.08916766941547394,
        "eval_rewards/accuracies": 0.39423078298568726,
        "eval_rewards/margins": 0.02819354645907879,
        "eval_logps/chosen": -298.6153869628906,
        "eval_logps/rejected": -271.19232177734375,
        "eval_logits/chosen": -0.8245192170143127,
        "eval_logits/rejected": -0.8861178159713745,
        "epoch": 0.18,
        "step": 30
    },
    {
        "loss": 0.6859,
        "grad_norm": 77.73289489746094,
        "learning_rate": 4.4161676646706585e-07,
        "rewards/chosen": 0.13257649540901184,
        "rewards/rejected": 0.11359049379825592,
        "rewards/accuracies": 0.4000000059604645,
        "rewards/margins": 0.01907246932387352,
        "logps/chosen": -303.8333435058594,
        "logps/rejected": -318.23333740234375,
        "logits/chosen": -0.7941080927848816,
        "logits/rejected": -0.7196289300918579,
        "epoch": 0.24,
        "step": 40
    },
    {
        "eval_loss": 0.678515613079071,
        "eval_runtime": 8.4084,
        "eval_samples_per_second": 11.893,
        "eval_steps_per_second": 1.546,
        "eval_rewards/chosen": 0.16883262991905212,
        "eval_rewards/rejected": 0.13718825578689575,
        "eval_rewards/accuracies": 0.4134615361690521,
        "eval_rewards/margins": 0.03167724609375,
        "eval_logps/chosen": -298.30767822265625,
        "eval_logps/rejected": -270.80767822265625,
        "eval_logits/chosen": -0.8299278616905212,
        "eval_logits/rejected": -0.889723539352417,
        "epoch": 0.24,
        "step": 40
    },
    {
        "loss": 0.6733,
        "grad_norm": 62.74578857421875,
        "learning_rate": 4.266467065868263e-07,
        "rewards/chosen": 0.18026529252529144,
        "rewards/rejected": 0.13297322392463684,
        "rewards/accuracies": 0.574999988079071,
        "rewards/margins": 0.04732869565486908,
        "logps/chosen": -263.07501220703125,
        "logps/rejected": -327.6833190917969,
        "logits/chosen": -0.6460123658180237,
        "logits/rejected": -0.6468912959098816,
        "epoch": 0.3,
        "step": 50
    },
    {
        "eval_loss": 0.6665624976158142,
        "eval_runtime": 8.5074,
        "eval_samples_per_second": 11.754,
        "eval_steps_per_second": 1.528,
        "eval_rewards/chosen": 0.23332332074642181,
        "eval_rewards/rejected": 0.17007210850715637,
        "eval_rewards/accuracies": 0.4711538553237915,
        "eval_rewards/margins": 0.06364558637142181,
        "eval_logps/chosen": -297.5769348144531,
        "eval_logps/rejected": -270.4615478515625,
        "eval_logits/chosen": -0.83203125,
        "eval_logits/rejected": -0.8927283883094788,
        "epoch": 0.3,
        "step": 50
    },
    {
        "loss": 0.6851,
        "grad_norm": 47.04432678222656,
        "learning_rate": 4.116766467065868e-07,
        "rewards/chosen": 0.22133788466453552,
        "rewards/rejected": 0.19561360776424408,
        "rewards/accuracies": 0.4833333194255829,
        "rewards/margins": 0.02578124962747097,
        "logps/chosen": -237.4583282470703,
        "logps/rejected": -245.0,
        "logits/chosen": -0.8134602904319763,
        "logits/rejected": -0.7927571535110474,
        "epoch": 0.36,
        "step": 60
    },
    {
        "eval_loss": 0.6727343797683716,
        "eval_runtime": 8.4332,
        "eval_samples_per_second": 11.858,
        "eval_steps_per_second": 1.542,
        "eval_rewards/chosen": 0.24879807233810425,
        "eval_rewards/rejected": 0.19037334620952606,
        "eval_rewards/accuracies": 0.48076921701431274,
        "eval_rewards/margins": 0.05817119777202606,
        "eval_logps/chosen": -297.1538391113281,
        "eval_logps/rejected": -270.3461608886719,
        "eval_logits/chosen": -0.8344351053237915,
        "eval_logits/rejected": -0.8960336446762085,
        "epoch": 0.36,
        "step": 60
    },
    {
        "loss": 0.6794,
        "grad_norm": 120.70286560058594,
        "learning_rate": 3.967065868263473e-07,
        "rewards/chosen": 0.23058268427848816,
        "rewards/rejected": 0.18864746391773224,
        "rewards/accuracies": 0.46666666865348816,
        "rewards/margins": 0.04197997972369194,
        "logps/chosen": -303.0666809082031,
        "logps/rejected": -316.85833740234375,
        "logits/chosen": -0.7828776240348816,
        "logits/rejected": -0.7891275882720947,
        "epoch": 0.42,
        "step": 70
    },
    {
        "eval_loss": 0.6553124785423279,
        "eval_runtime": 8.4233,
        "eval_samples_per_second": 11.872,
        "eval_steps_per_second": 1.543,
        "eval_rewards/chosen": 0.2948467433452606,
        "eval_rewards/rejected": 0.21082481741905212,
        "eval_rewards/accuracies": 0.5,
        "eval_rewards/margins": 0.08412522822618484,
        "eval_logps/chosen": -296.8846130371094,
        "eval_logps/rejected": -270.26922607421875,
        "eval_logits/chosen": -0.8359375,
        "eval_logits/rejected": -0.8966346383094788,
        "epoch": 0.42,
        "step": 70
    },
    {
        "loss": 0.677,
        "grad_norm": 88.43953704833984,
        "learning_rate": 3.8173652694610777e-07,
        "rewards/chosen": 0.23693034052848816,
        "rewards/rejected": 0.19939778745174408,
        "rewards/accuracies": 0.4833333194255829,
        "rewards/margins": 0.03752034530043602,
        "logps/chosen": -222.625,
        "logps/rejected": -238.44166564941406,
        "logits/chosen": -0.7182454466819763,
        "logits/rejected": -0.6988932490348816,
        "epoch": 0.48,
        "step": 80
    },
    {
        "eval_loss": 0.6547265648841858,
        "eval_runtime": 8.4384,
        "eval_samples_per_second": 11.851,
        "eval_steps_per_second": 1.541,
        "eval_rewards/chosen": 0.2841796875,
        "eval_rewards/rejected": 0.19108699262142181,
        "eval_rewards/accuracies": 0.557692289352417,
        "eval_rewards/margins": 0.09346830099821091,
        "eval_logps/chosen": -297.1538391113281,
        "eval_logps/rejected": -270.30767822265625,
        "eval_logits/chosen": -0.838942289352417,
        "eval_logits/rejected": -0.8981370329856873,
        "epoch": 0.48,
        "step": 80
    },
    {
        "loss": 0.6885,
        "grad_norm": 50.79372787475586,
        "learning_rate": 3.6676646706586824e-07,
        "rewards/chosen": 0.20766600966453552,
        "rewards/rejected": 0.1945393830537796,
        "rewards/accuracies": 0.4416666626930237,
        "rewards/margins": 0.01286214217543602,
        "logps/chosen": -250.1666717529297,
        "logps/rejected": -252.28334045410156,
        "logits/chosen": -0.7068033814430237,
        "logits/rejected": -0.693286120891571,
        "epoch": 0.54,
        "step": 90
    },
    {
        "eval_loss": 0.6571484208106995,
        "eval_runtime": 8.442,
        "eval_samples_per_second": 11.846,
        "eval_steps_per_second": 1.54,
        "eval_rewards/chosen": 0.2823016941547394,
        "eval_rewards/rejected": 0.189453125,
        "eval_rewards/accuracies": 0.5769230723381042,
        "eval_rewards/margins": 0.09256685525178909,
        "eval_logps/chosen": -297.0384521484375,
        "eval_logps/rejected": -270.3461608886719,
        "eval_logits/chosen": -0.8404446840286255,
        "eval_logits/rejected": -0.9002403616905212,
        "epoch": 0.54,
        "step": 90
    },
    {
        "loss": 0.6559,
        "grad_norm": 82.58587646484375,
        "learning_rate": 3.5179640718562876e-07,
        "rewards/chosen": 0.2771158814430237,
        "rewards/rejected": 0.19373372197151184,
        "rewards/accuracies": 0.550000011920929,
        "rewards/margins": 0.08343912661075592,
        "logps/chosen": -334.8333435058594,
        "logps/rejected": -295.1499938964844,
        "logits/chosen": -0.7922526001930237,
        "logits/rejected": -0.83984375,
        "epoch": 0.6,
        "step": 100
    },
    {
        "eval_loss": 0.6543750166893005,
        "eval_runtime": 8.4081,
        "eval_samples_per_second": 11.893,
        "eval_steps_per_second": 1.546,
        "eval_rewards/chosen": 0.3007061183452606,
        "eval_rewards/rejected": 0.20808292925357819,
        "eval_rewards/accuracies": 0.5288461446762085,
        "eval_rewards/margins": 0.09197528660297394,
        "eval_logps/chosen": -296.8461608886719,
        "eval_logps/rejected": -270.23077392578125,
        "eval_logits/chosen": -0.842848539352417,
        "eval_logits/rejected": -0.9002403616905212,
        "epoch": 0.6,
        "step": 100
    },
    {
        "loss": 0.6549,
        "grad_norm": 68.12452697753906,
        "learning_rate": 3.368263473053892e-07,
        "rewards/chosen": 0.2972859740257263,
        "rewards/rejected": 0.20786133408546448,
        "rewards/accuracies": 0.5416666865348816,
        "rewards/margins": 0.0892740860581398,
        "logps/chosen": -275.4083251953125,
        "logps/rejected": -215.94166564941406,
        "logits/chosen": -0.7742838263511658,
        "logits/rejected": -0.7723633050918579,
        "epoch": 0.66,
        "step": 110
    },
    {
        "eval_loss": 0.6462500095367432,
        "eval_runtime": 8.4184,
        "eval_samples_per_second": 11.879,
        "eval_steps_per_second": 1.544,
        "eval_rewards/chosen": 0.31911057233810425,
        "eval_rewards/rejected": 0.20241135358810425,
        "eval_rewards/accuracies": 0.5865384340286255,
        "eval_rewards/margins": 0.11668043583631516,
        "eval_logps/chosen": -296.73077392578125,
        "eval_logps/rejected": -270.26922607421875,
        "eval_logits/chosen": -0.8410456776618958,
        "eval_logits/rejected": -0.9005408883094788,
        "epoch": 0.66,
        "step": 110
    },
    {
        "loss": 0.6755,
        "grad_norm": 43.63288497924805,
        "learning_rate": 3.218562874251497e-07,
        "rewards/chosen": 0.27656251192092896,
        "rewards/rejected": 0.22797851264476776,
        "rewards/accuracies": 0.44999998807907104,
        "rewards/margins": 0.04876708984375,
        "logps/chosen": -211.69583129882812,
        "logps/rejected": -211.17083740234375,
        "logits/chosen": -0.724365234375,
        "logits/rejected": -0.7136881351470947,
        "epoch": 0.72,
        "step": 120
    },
    {
        "eval_loss": 0.6364843845367432,
        "eval_runtime": 8.4298,
        "eval_samples_per_second": 11.863,
        "eval_steps_per_second": 1.542,
        "eval_rewards/chosen": 0.3511117696762085,
        "eval_rewards/rejected": 0.22340744733810425,
        "eval_rewards/accuracies": 0.625,
        "eval_rewards/margins": 0.12741324305534363,
        "eval_logps/chosen": -296.69232177734375,
        "eval_logps/rejected": -270.0769348144531,
        "eval_logits/chosen": -0.8422476053237915,
        "eval_logits/rejected": -0.9020432829856873,
        "epoch": 0.72,
        "step": 120
    },
    {
        "loss": 0.6617,
        "grad_norm": 113.27629852294922,
        "learning_rate": 3.0688622754491015e-07,
        "rewards/chosen": 0.3210286498069763,
        "rewards/rejected": 0.2379353791475296,
        "rewards/accuracies": 0.5583333373069763,
        "rewards/margins": 0.08324889838695526,
        "logps/chosen": -234.5625,
        "logps/rejected": -205.0500030517578,
        "logits/chosen": -0.740039050579071,
        "logits/rejected": -0.6821207404136658,
        "epoch": 0.78,
        "step": 130
    },
    {
        "eval_loss": 0.642773449420929,
        "eval_runtime": 8.4329,
        "eval_samples_per_second": 11.858,
        "eval_steps_per_second": 1.542,
        "eval_rewards/chosen": 0.4057992696762085,
        "eval_rewards/rejected": 0.28481820225715637,
        "eval_rewards/accuracies": 0.6057692170143127,
        "eval_rewards/margins": 0.12084022164344788,
        "eval_logps/chosen": -295.8846130371094,
        "eval_logps/rejected": -269.4615478515625,
        "eval_logits/chosen": -0.842848539352417,
        "eval_logits/rejected": -0.9017428159713745,
        "epoch": 0.78,
        "step": 130
    },
    {
        "loss": 0.6658,
        "grad_norm": 82.4394302368164,
        "learning_rate": 2.919161676646706e-07,
        "rewards/chosen": 0.3687906861305237,
        "rewards/rejected": 0.3009602725505829,
        "rewards/accuracies": 0.5833333134651184,
        "rewards/margins": 0.06798502802848816,
        "logps/chosen": -216.61666870117188,
        "logps/rejected": -227.47500610351562,
        "logits/chosen": -0.7257161736488342,
        "logits/rejected": -0.7782307863235474,
        "epoch": 0.84,
        "step": 140
    },
    {
        "eval_loss": 0.6308984160423279,
        "eval_runtime": 8.4273,
        "eval_samples_per_second": 11.866,
        "eval_steps_per_second": 1.543,
        "eval_rewards/chosen": 0.4585336446762085,
        "eval_rewards/rejected": 0.3060396611690521,
        "eval_rewards/accuracies": 0.6730769276618958,
        "eval_rewards/margins": 0.1528695970773697,
        "eval_logps/chosen": -295.23077392578125,
        "eval_logps/rejected": -269.26922607421875,
        "eval_logits/chosen": -0.8416466116905212,
        "eval_logits/rejected": -0.9020432829856873,
        "epoch": 0.84,
        "step": 140
    },
    {
        "loss": 0.6778,
        "grad_norm": 91.79827117919922,
        "learning_rate": 2.7694610778443114e-07,
        "rewards/chosen": 0.3858073055744171,
        "rewards/rejected": 0.3180989623069763,
        "rewards/accuracies": 0.5249999761581421,
        "rewards/margins": 0.06768392026424408,
        "logps/chosen": -302.6499938964844,
        "logps/rejected": -361.2916564941406,
        "logits/chosen": -0.8658854365348816,
        "logits/rejected": -0.8291666507720947,
        "epoch": 0.9,
        "step": 150
    },
    {
        "eval_loss": 0.6307031512260437,
        "eval_runtime": 8.4009,
        "eval_samples_per_second": 11.904,
        "eval_steps_per_second": 1.547,
        "eval_rewards/chosen": 0.4701021611690521,
        "eval_rewards/rejected": 0.32241585850715637,
        "eval_rewards/accuracies": 0.625,
        "eval_rewards/margins": 0.14789287745952606,
        "eval_logps/chosen": -294.9230651855469,
        "eval_logps/rejected": -269.1153869628906,
        "eval_logits/chosen": -0.8434495329856873,
        "eval_logits/rejected": -0.9026442170143127,
        "epoch": 0.9,
        "step": 150
    },
    {
        "loss": 0.6529,
        "grad_norm": 54.68354415893555,
        "learning_rate": 2.619760479041916e-07,
        "rewards/chosen": 0.4358072876930237,
        "rewards/rejected": 0.3303059935569763,
        "rewards/accuracies": 0.5666666626930237,
        "rewards/margins": 0.105712890625,
        "logps/chosen": -242.64166259765625,
        "logps/rejected": -206.0833282470703,
        "logits/chosen": -0.8003906011581421,
        "logits/rejected": -0.8359375,
        "epoch": 0.96,
        "step": 160
    },
    {
        "eval_loss": 0.6285156011581421,
        "eval_runtime": 8.3964,
        "eval_samples_per_second": 11.91,
        "eval_steps_per_second": 1.548,
        "eval_rewards/chosen": 0.4915865361690521,
        "eval_rewards/rejected": 0.33511117100715637,
        "eval_rewards/accuracies": 0.6634615659713745,
        "eval_rewards/margins": 0.1567758470773697,
        "eval_logps/chosen": -294.6538391113281,
        "eval_logps/rejected": -268.9230651855469,
        "eval_logits/chosen": -0.8440504670143127,
        "eval_logits/rejected": -0.9026442170143127,
        "epoch": 0.96,
        "step": 160
    },
    {
        "loss": 0.6088,
        "grad_norm": 48.07950973510742,
        "learning_rate": 2.4700598802395207e-07,
        "rewards/chosen": 0.5731074810028076,
        "rewards/rejected": 0.1348666548728943,
        "rewards/accuracies": 0.5948275923728943,
        "rewards/margins": 0.4386196732521057,
        "logps/chosen": -201.5689697265625,
        "logps/rejected": -265.862060546875,
        "logits/chosen": -0.6591964960098267,
        "logits/rejected": -0.6752424836158752,
        "epoch": 1.018,
        "step": 170
    },
    {
        "eval_loss": 0.6087109446525574,
        "eval_runtime": 8.3926,
        "eval_samples_per_second": 11.915,
        "eval_steps_per_second": 1.549,
        "eval_rewards/chosen": 0.5172776579856873,
        "eval_rewards/rejected": 0.32046273350715637,
        "eval_rewards/accuracies": 0.6634615659713745,
        "eval_rewards/margins": 0.19591346383094788,
        "eval_logps/chosen": -294.6538391113281,
        "eval_logps/rejected": -268.9230651855469,
        "eval_logits/chosen": -0.8458533883094788,
        "eval_logits/rejected": -0.9047476053237915,
        "epoch": 1.018,
        "step": 170
    },
    {
        "loss": 0.538,
        "grad_norm": 52.043479919433594,
        "learning_rate": 2.3203592814371256e-07,
        "rewards/chosen": 0.7559896111488342,
        "rewards/rejected": 0.0812174454331398,
        "rewards/accuracies": 0.6166666746139526,
        "rewards/margins": 0.6748697757720947,
        "logps/chosen": -226.61666870117188,
        "logps/rejected": -227.12083435058594,
        "logits/chosen": -0.7693196535110474,
        "logits/rejected": -0.798535168170929,
        "epoch": 1.078,
        "step": 180
    },
    {
        "eval_loss": 0.6126562356948853,
        "eval_runtime": 8.392,
        "eval_samples_per_second": 11.916,
        "eval_steps_per_second": 1.549,
        "eval_rewards/chosen": 0.5911959409713745,
        "eval_rewards/rejected": 0.40061599016189575,
        "eval_rewards/accuracies": 0.6634615659713745,
        "eval_rewards/margins": 0.19121845066547394,
        "eval_logps/chosen": -293.9615478515625,
        "eval_logps/rejected": -268.3461608886719,
        "eval_logits/chosen": -0.8470553159713745,
        "eval_logits/rejected": -0.905348539352417,
        "epoch": 1.078,
        "step": 180
    },
    {
        "loss": 0.5301,
        "grad_norm": 28.324161529541016,
        "learning_rate": 2.1706586826347303e-07,
        "rewards/chosen": 0.8999348878860474,
        "rewards/rejected": 0.15099284052848816,
        "rewards/accuracies": 0.6499999761581421,
        "rewards/margins": 0.749462902545929,
        "logps/chosen": -283.2416687011719,
        "logps/rejected": -297.95416259765625,
        "logits/chosen": -0.754833996295929,
        "logits/rejected": -0.7983723878860474,
        "epoch": 1.138,
        "step": 190
    },
    {
        "eval_loss": 0.6143359541893005,
        "eval_runtime": 8.4032,
        "eval_samples_per_second": 11.9,
        "eval_steps_per_second": 1.547,
        "eval_rewards/chosen": 0.6643629670143127,
        "eval_rewards/rejected": 0.46762320399284363,
        "eval_rewards/accuracies": 0.6730769276618958,
        "eval_rewards/margins": 0.19677734375,
        "eval_logps/chosen": -293.4615478515625,
        "eval_logps/rejected": -267.6153869628906,
        "eval_logits/chosen": -0.8479567170143127,
        "eval_logits/rejected": -0.9080528616905212,
        "epoch": 1.138,
        "step": 190
    },
    {
        "loss": 0.4871,
        "grad_norm": 80.44483947753906,
        "learning_rate": 2.0209580838323352e-07,
        "rewards/chosen": 1.0904947519302368,
        "rewards/rejected": 0.08084309846162796,
        "rewards/accuracies": 0.699999988079071,
        "rewards/margins": 1.009521484375,
        "logps/chosen": -263.85833740234375,
        "logps/rejected": -250.63333129882812,
        "logits/chosen": -0.818164050579071,
        "logits/rejected": -0.7980143427848816,
        "epoch": 1.198,
        "step": 200
    },
    {
        "eval_loss": 0.6054297089576721,
        "eval_runtime": 8.3867,
        "eval_samples_per_second": 11.924,
        "eval_steps_per_second": 1.55,
        "eval_rewards/chosen": 0.7088341116905212,
        "eval_rewards/rejected": 0.4965444803237915,
        "eval_rewards/accuracies": 0.6730769276618958,
        "eval_rewards/margins": 0.21161358058452606,
        "eval_logps/chosen": -292.76922607421875,
        "eval_logps/rejected": -267.26922607421875,
        "eval_logits/chosen": -0.850661039352417,
        "eval_logits/rejected": -0.9104567170143127,
        "epoch": 1.198,
        "step": 200
    },
    {
        "loss": 0.5186,
        "grad_norm": 40.100337982177734,
        "learning_rate": 1.8712574850299402e-07,
        "rewards/chosen": 0.8870442509651184,
        "rewards/rejected": 0.1771647185087204,
        "rewards/accuracies": 0.7083333134651184,
        "rewards/margins": 0.7104166746139526,
        "logps/chosen": -245.8000030517578,
        "logps/rejected": -233.0749969482422,
        "logits/chosen": -0.746044933795929,
        "logits/rejected": -0.7498576045036316,
        "epoch": 1.258,
        "step": 210
    },
    {
        "eval_loss": 0.5941406488418579,
        "eval_runtime": 8.3909,
        "eval_samples_per_second": 11.918,
        "eval_steps_per_second": 1.549,
        "eval_rewards/chosen": 0.7244591116905212,
        "eval_rewards/rejected": 0.4858773946762085,
        "eval_rewards/accuracies": 0.7019230723381042,
        "eval_rewards/margins": 0.23858173191547394,
        "eval_logps/chosen": -292.76922607421875,
        "eval_logps/rejected": -267.3846130371094,
        "eval_logits/chosen": -0.8512620329856873,
        "eval_logits/rejected": -0.9098557829856873,
        "epoch": 1.258,
        "step": 210
    },
    {
        "loss": 0.5414,
        "grad_norm": 48.37976837158203,
        "learning_rate": 1.7215568862275448e-07,
        "rewards/chosen": 0.934374988079071,
        "rewards/rejected": 0.3522135317325592,
        "rewards/accuracies": 0.7166666388511658,
        "rewards/margins": 0.5827066898345947,
        "logps/chosen": -275.20001220703125,
        "logps/rejected": -326.3833312988281,
        "logits/chosen": -0.8177897334098816,
        "logits/rejected": -0.803906261920929,
        "epoch": 1.318,
        "step": 220
    },
    {
        "eval_loss": 0.6030077934265137,
        "eval_runtime": 8.3942,
        "eval_samples_per_second": 11.913,
        "eval_steps_per_second": 1.549,
        "eval_rewards/chosen": 0.7376803159713745,
        "eval_rewards/rejected": 0.5163761973381042,
        "eval_rewards/accuracies": 0.692307710647583,
        "eval_rewards/margins": 0.2211538404226303,
        "eval_logps/chosen": -292.6153869628906,
        "eval_logps/rejected": -267.26922607421875,
        "eval_logits/chosen": -0.8527644276618958,
        "eval_logits/rejected": -0.9119591116905212,
        "epoch": 1.318,
        "step": 220
    },
    {
        "loss": 0.5048,
        "grad_norm": 79.2493896484375,
        "learning_rate": 1.5718562874251495e-07,
        "rewards/chosen": 1.006250023841858,
        "rewards/rejected": 0.22551269829273224,
        "rewards/accuracies": 0.75,
        "rewards/margins": 0.7811523675918579,
        "logps/chosen": -223.47500610351562,
        "logps/rejected": -203.7083282470703,
        "logits/chosen": -0.6804524660110474,
        "logits/rejected": -0.690478503704071,
        "epoch": 1.3780000000000001,
        "step": 230
    },
    {
        "eval_loss": 0.5950390696525574,
        "eval_runtime": 8.4228,
        "eval_samples_per_second": 11.872,
        "eval_steps_per_second": 1.543,
        "eval_rewards/chosen": 0.7830528616905212,
        "eval_rewards/rejected": 0.534254789352417,
        "eval_rewards/accuracies": 0.682692289352417,
        "eval_rewards/margins": 0.2490234375,
        "eval_logps/chosen": -292.19232177734375,
        "eval_logps/rejected": -267.0769348144531,
        "eval_logits/chosen": -0.85546875,
        "eval_logits/rejected": -0.9155648946762085,
        "epoch": 1.3780000000000001,
        "step": 230
    },
    {
        "loss": 0.5148,
        "grad_norm": 23.503915786743164,
        "learning_rate": 1.4221556886227547e-07,
        "rewards/chosen": 1.1311849355697632,
        "rewards/rejected": 0.2135416716337204,
        "rewards/accuracies": 0.6666666865348816,
        "rewards/margins": 0.9169759154319763,
        "logps/chosen": -260.4666748046875,
        "logps/rejected": -259.0916748046875,
        "logits/chosen": -0.7631510496139526,
        "logits/rejected": -0.7564778923988342,
        "epoch": 1.438,
        "step": 240
    },
    {
        "eval_loss": 0.5860156416893005,
        "eval_runtime": 8.4317,
        "eval_samples_per_second": 11.86,
        "eval_steps_per_second": 1.542,
        "eval_rewards/chosen": 0.8371394276618958,
        "eval_rewards/rejected": 0.5728665590286255,
        "eval_rewards/accuracies": 0.7019230723381042,
        "eval_rewards/margins": 0.2641226053237915,
        "eval_logps/chosen": -291.80767822265625,
        "eval_logps/rejected": -267.0384521484375,
        "eval_logits/chosen": -0.856370210647583,
        "eval_logits/rejected": -0.9158653616905212,
        "epoch": 1.438,
        "step": 240
    },
    {
        "loss": 0.5113,
        "grad_norm": 16.179643630981445,
        "learning_rate": 1.2724550898203593e-07,
        "rewards/chosen": 1.1140625476837158,
        "rewards/rejected": 0.25491535663604736,
        "rewards/accuracies": 0.6166666746139526,
        "rewards/margins": 0.8602457642555237,
        "logps/chosen": -239.03750610351562,
        "logps/rejected": -330.7875061035156,
        "logits/chosen": -0.8407552242279053,
        "logits/rejected": -0.791210949420929,
        "epoch": 1.498,
        "step": 250
    },
    {
        "eval_loss": 0.5892578363418579,
        "eval_runtime": 8.4242,
        "eval_samples_per_second": 11.871,
        "eval_steps_per_second": 1.543,
        "eval_rewards/chosen": 0.90234375,
        "eval_rewards/rejected": 0.639723539352417,
        "eval_rewards/accuracies": 0.7211538553237915,
        "eval_rewards/margins": 0.2628079950809479,
        "eval_logps/chosen": -291.1538391113281,
        "eval_logps/rejected": -265.8846130371094,
        "eval_logits/chosen": -0.856370210647583,
        "eval_logits/rejected": -0.917067289352417,
        "epoch": 1.498,
        "step": 250
    },
    {
        "loss": 0.5333,
        "grad_norm": 68.70392608642578,
        "learning_rate": 1.122754491017964e-07,
        "rewards/chosen": 1.0701823234558105,
        "rewards/rejected": 0.36038410663604736,
        "rewards/accuracies": 0.6833333373069763,
        "rewards/margins": 0.7097981572151184,
        "logps/chosen": -255.10000610351562,
        "logps/rejected": -291.7083435058594,
        "logits/chosen": -0.8022135496139526,
        "logits/rejected": -0.7561197876930237,
        "epoch": 1.558,
        "step": 260
    },
    {
        "eval_loss": 0.5844922065734863,
        "eval_runtime": 8.426,
        "eval_samples_per_second": 11.868,
        "eval_steps_per_second": 1.543,
        "eval_rewards/chosen": 0.9275841116905212,
        "eval_rewards/rejected": 0.66015625,
        "eval_rewards/accuracies": 0.692307710647583,
        "eval_rewards/margins": 0.2675029933452606,
        "eval_logps/chosen": -290.8846130371094,
        "eval_logps/rejected": -265.5769348144531,
        "eval_logits/chosen": -0.8605769276618958,
        "eval_logits/rejected": -0.91796875,
        "epoch": 1.558,
        "step": 260
    },
    {
        "loss": 0.5359,
        "grad_norm": 66.19377136230469,
        "learning_rate": 9.730538922155689e-08,
        "rewards/chosen": 1.1026041507720947,
        "rewards/rejected": 0.39892578125,
        "rewards/accuracies": 0.6583333611488342,
        "rewards/margins": 0.7041178345680237,
        "logps/chosen": -268.0833435058594,
        "logps/rejected": -232.13333129882812,
        "logits/chosen": -0.8851562738418579,
        "logits/rejected": -0.8426269292831421,
        "epoch": 1.6179999999999999,
        "step": 270
    },
    {
        "eval_loss": 0.5873827934265137,
        "eval_runtime": 8.4221,
        "eval_samples_per_second": 11.874,
        "eval_steps_per_second": 1.544,
        "eval_rewards/chosen": 0.917067289352417,
        "eval_rewards/rejected": 0.6490384340286255,
        "eval_rewards/accuracies": 0.7211538553237915,
        "eval_rewards/margins": 0.26832932233810425,
        "eval_logps/chosen": -290.80767822265625,
        "eval_logps/rejected": -265.69232177734375,
        "eval_logits/chosen": -0.859375,
        "eval_logits/rejected": -0.9173678159713745,
        "epoch": 1.6179999999999999,
        "step": 270
    },
    {
        "loss": 0.4807,
        "grad_norm": 39.92721176147461,
        "learning_rate": 8.233532934131736e-08,
        "rewards/chosen": 1.1787760257720947,
        "rewards/rejected": 0.2964843809604645,
        "rewards/accuracies": 0.7833333611488342,
        "rewards/margins": 0.8829264044761658,
        "logps/chosen": -216.38333129882812,
        "logps/rejected": -276.0333251953125,
        "logits/chosen": -0.7132161259651184,
        "logits/rejected": -0.6852945685386658,
        "epoch": 1.678,
        "step": 280
    },
    {
        "eval_loss": 0.5804687738418579,
        "eval_runtime": 8.4244,
        "eval_samples_per_second": 11.87,
        "eval_steps_per_second": 1.543,
        "eval_rewards/chosen": 0.9317908883094788,
        "eval_rewards/rejected": 0.6478365659713745,
        "eval_rewards/accuracies": 0.7307692170143127,
        "eval_rewards/margins": 0.2835787236690521,
        "eval_logps/chosen": -290.19232177734375,
        "eval_logps/rejected": -265.6538391113281,
        "eval_logits/chosen": -0.860276460647583,
        "eval_logits/rejected": -0.9185696840286255,
        "epoch": 1.678,
        "step": 280
    },
    {
        "loss": 0.5044,
        "grad_norm": 38.68849563598633,
        "learning_rate": 6.736526946107785e-08,
        "rewards/chosen": 1.1802083253860474,
        "rewards/rejected": 0.358642578125,
        "rewards/accuracies": 0.75,
        "rewards/margins": 0.8219238519668579,
        "logps/chosen": -292.1833190917969,
        "logps/rejected": -260.2166748046875,
        "logits/chosen": -0.8783203363418579,
        "logits/rejected": -0.8397786617279053,
        "epoch": 1.738,
        "step": 290
    },
    {
        "eval_loss": 0.5774219036102295,
        "eval_runtime": 8.4258,
        "eval_samples_per_second": 11.868,
        "eval_steps_per_second": 1.543,
        "eval_rewards/chosen": 0.9347956776618958,
        "eval_rewards/rejected": 0.6517428159713745,
        "eval_rewards/accuracies": 0.7211538553237915,
        "eval_rewards/margins": 0.28346604108810425,
        "eval_logps/chosen": -290.5,
        "eval_logps/rejected": -265.8461608886719,
        "eval_logits/chosen": -0.8620793223381042,
        "eval_logits/rejected": -0.9203726053237915,
        "epoch": 1.738,
        "step": 290
    },
    {
        "loss": 0.4804,
        "grad_norm": 44.2522087097168,
        "learning_rate": 5.2395209580838316e-08,
        "rewards/chosen": 1.231835961341858,
        "rewards/rejected": 0.22826537489891052,
        "rewards/accuracies": 0.75,
        "rewards/margins": 1.0043456554412842,
        "logps/chosen": -272.875,
        "logps/rejected": -268.8166809082031,
        "logits/chosen": -0.7925130128860474,
        "logits/rejected": -0.8054036498069763,
        "epoch": 1.798,
        "step": 300
    },
    {
        "eval_loss": 0.582812488079071,
        "eval_runtime": 8.4292,
        "eval_samples_per_second": 11.863,
        "eval_steps_per_second": 1.542,
        "eval_rewards/chosen": 0.9197716116905212,
        "eval_rewards/rejected": 0.639723539352417,
        "eval_rewards/accuracies": 0.692307710647583,
        "eval_rewards/margins": 0.279296875,
        "eval_logps/chosen": -290.5,
        "eval_logps/rejected": -265.9230651855469,
        "eval_logits/chosen": -0.8620793223381042,
        "eval_logits/rejected": -0.9206730723381042,
        "epoch": 1.798,
        "step": 300
    },
    {
        "loss": 0.5291,
        "grad_norm": 48.876304626464844,
        "learning_rate": 3.7425149700598795e-08,
        "rewards/chosen": 1.1626302003860474,
        "rewards/rejected": 0.3984375,
        "rewards/accuracies": 0.7083333134651184,
        "rewards/margins": 0.7647135257720947,
        "logps/chosen": -239.28334045410156,
        "logps/rejected": -239.13333129882812,
        "logits/chosen": -0.7730143070220947,
        "logits/rejected": -0.774218738079071,
        "epoch": 1.858,
        "step": 310
    },
    {
        "eval_loss": 0.5707812309265137,
        "eval_runtime": 8.4155,
        "eval_samples_per_second": 11.883,
        "eval_steps_per_second": 1.545,
        "eval_rewards/chosen": 0.9155648946762085,
        "eval_rewards/rejected": 0.6125300526618958,
        "eval_rewards/accuracies": 0.7403846383094788,
        "eval_rewards/margins": 0.30348557233810425,
        "eval_logps/chosen": -290.80767822265625,
        "eval_logps/rejected": -265.8846130371094,
        "eval_logits/chosen": -0.8620793223381042,
        "eval_logits/rejected": -0.9206730723381042,
        "epoch": 1.858,
        "step": 310
    },
    {
        "loss": 0.4992,
        "grad_norm": 63.8978271484375,
        "learning_rate": 2.245508982035928e-08,
        "rewards/chosen": 1.1934244632720947,
        "rewards/rejected": 0.3076985776424408,
        "rewards/accuracies": 0.699999988079071,
        "rewards/margins": 0.8855956792831421,
        "logps/chosen": -253.83438110351562,
        "logps/rejected": -231.46041870117188,
        "logits/chosen": -0.7041951417922974,
        "logits/rejected": -0.7052897214889526,
        "epoch": 1.9180000000000001,
        "step": 320
    },
    {
        "eval_loss": 0.5658593773841858,
        "eval_runtime": 8.4116,
        "eval_samples_per_second": 11.888,
        "eval_steps_per_second": 1.545,
        "eval_rewards/chosen": 0.9251803159713745,
        "eval_rewards/rejected": 0.6039663553237915,
        "eval_rewards/accuracies": 0.7692307829856873,
        "eval_rewards/margins": 0.3212890625,
        "eval_logps/chosen": -290.3461608886719,
        "eval_logps/rejected": -266.26922607421875,
        "eval_logits/chosen": -0.86328125,
        "eval_logits/rejected": -0.9215745329856873,
        "epoch": 1.9180000000000001,
        "step": 320
    },
    {
        "loss": 0.4994,
        "grad_norm": 38.759918212890625,
        "learning_rate": 7.48502994011976e-09,
        "rewards/chosen": 1.1677082777023315,
        "rewards/rejected": 0.32325032353401184,
        "rewards/accuracies": 0.75,
        "rewards/margins": 0.8449381589889526,
        "logps/chosen": -251.05833435058594,
        "logps/rejected": -241.5833282470703,
        "logits/chosen": -0.7636881470680237,
        "logits/rejected": -0.6861979365348816,
        "epoch": 1.978,
        "step": 330
    },
    {
        "eval_loss": 0.5702343583106995,
        "eval_runtime": 8.4316,
        "eval_samples_per_second": 11.86,
        "eval_steps_per_second": 1.542,
        "eval_rewards/chosen": 0.924879789352417,
        "eval_rewards/rejected": 0.6147836446762085,
        "eval_rewards/accuracies": 0.7596153616905212,
        "eval_rewards/margins": 0.30979567766189575,
        "eval_logps/chosen": -290.6538391113281,
        "eval_logps/rejected": -266.1538391113281,
        "eval_logits/chosen": -0.862379789352417,
        "eval_logits/rejected": -0.921875,
        "epoch": 1.978,
        "step": 330
    },
    {
        "train_runtime": 2296.2209,
        "train_samples_per_second": 1.742,
        "train_steps_per_second": 0.145,
        "total_flos": 0.0,
        "train_loss": 0.5898568772984122,
        "epoch": 2.0,
        "step": 334
    }
]